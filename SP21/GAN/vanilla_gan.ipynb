{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our simple vanilla generator\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Architecture\n",
    "    ------------\n",
    "    Latent Input: latent_shape\n",
    "    Flattened\n",
    "    Linear MLP(256, 512, 1024, prod(img_shape))\n",
    "\n",
    "    Leaky Relu activation after every layer except last. (Important!)\n",
    "    Tanh activation after last layer to normalize\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_shape, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_shape = img_shape\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(np.prod(latent_shape), 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, np.prod(img_shape)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        # reshape into a image\n",
    "        return self.mlp(x).reshape(batch_size, 1, *self.img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our simple vanilla discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Architecture\n",
    "    ------------\n",
    "    Input Image: img_shape\n",
    "    Flattened\n",
    "    Linear MLP(1024, 512, 256, 1)\n",
    "    Leaky Relu activation after every layer except last.\n",
    "    Sigmoid activation after last layer to normalize in range 0 to 1\n",
    "    \"\"\"\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(np.prod(img_shape), 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our data\n",
    "latent_shape = (28, 28)\n",
    "img_shape = (28, 28)\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train = True, download=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # for gpu usage if possible\n",
    "\n",
    "generator = Generator(latent_shape, img_shape)\n",
    "discriminator = Discriminator(img_shape)\n",
    "\n",
    "gen_optim = torch.optim.Adam(generator.parameters(), lr=2e-4)\n",
    "disc_optim = torch.optim.Adam(discriminator.parameters(), lr=2e-4)\n",
    "\n",
    "# .to(device) moves the networks / models to that device, which is either CPU or the GPU depending on what was detected\n",
    "# if moved to GPU, then the networks can make use of the GPU for computations which is much faster!\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, generator_optim: torch.optim, discriminator_optim: torch.optim, epochs=100):\n",
    "    adversarial_loss = torch.nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        avg_g_loss = 0\n",
    "        avg_d_loss = 0\n",
    "        \n",
    "        # notebook.tqdm is a nice way of displaying progress on a jupyter or colab notebook while we loop over the data in train_dataloader\n",
    "        pbar = notebook.tqdm(train_dataloader, total=len(train_dataloader))\n",
    "        i = 0\n",
    "        for data in pbar:\n",
    "            i += 1\n",
    "            real_images = data[0].to(device)\n",
    "            ### Train Generator ###\n",
    "\n",
    "            # .zero_grad() is important in PyTorch. Don't forget it. If you do, the optimizer won't work.\n",
    "            generator_optim.zero_grad()\n",
    "            \n",
    "            latent_input = torch.randn((len(real_images), 1, *latent_shape)).to(device)\n",
    "            fake_images = generator(latent_input)\n",
    "\n",
    "            fake_res = discriminator(fake_images)\n",
    "            \n",
    "            # we penalize the generator for being unable to make the discrminator predict 1s for generated fake images\n",
    "            generator_loss = adversarial_loss(fake_res, torch.ones_like(fake_res))\n",
    "\n",
    "            # .backward() computes gradients for the loss function with respect to anything that is not detached\n",
    "            generator_loss.backward()\n",
    "            # .step() uses a optimizer to apply the gradients to the model parameters, updating the model to reduce the loss\n",
    "            generator_optim.step()\n",
    "            \n",
    "            ### Train Discriminator ###\n",
    "            discriminator_optim.zero_grad()\n",
    "            \n",
    "            real_res = discriminator(real_images)\n",
    "\n",
    "            # .detach() removes fake_images variable from gradient computation, meaning our \n",
    "            # generator is not going to be updated when we use the optimizer\n",
    "            fake_res = discriminator(fake_images.detach())\n",
    "\n",
    "            # we penalize the discriminator for not predicting 1s for real images\n",
    "            discriminator_real_loss = adversarial_loss(real_res, torch.ones_like(real_res))\n",
    "            # we penalize the discriminator for not predicting 0s for generated, fake images\n",
    "            discriminator_fake_loss = adversarial_loss(fake_res, torch.zeros_like(real_res))\n",
    "            \n",
    "            discriminator_loss = (discriminator_real_loss + discriminator_fake_loss) / 2\n",
    "            \n",
    "            discriminator_loss.backward()\n",
    "            discriminator_optim.step()\n",
    "            \n",
    "\n",
    "            avg_g_loss += generator_loss.item()\n",
    "            avg_d_loss += discriminator_loss.item()\n",
    "            pbar.set_postfix({\"G_loss\": generator_loss.item(), \"D_loss\": discriminator_loss.item()})\n",
    "        print(\"Avg G_loss {} - Avg D_loss {}\".format(avg_g_loss / i, avg_d_loss / i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our generator and discriminator\n",
    "# Note: don't always expect loss to go down simultaneously for both models. They are competing against each other! So sometimes one model \n",
    "# may perform better than the other\n",
    "train(generator=generator, discriminator=discriminator, generator_optim=gen_optim, discriminator_optim=disc_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it out!\n",
    "latent_input = torch.randn((batch_size, 1, *latent_shape))\n",
    "test = generator(latent_input.to(device))\n",
    "plt.imshow(test[0].reshape(28, 28).cpu().detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python379jvsc74a57bd0c3e162dbea2a7bde87c7844ddb2ca1843aba08611dc435aaff358cdc82c48661"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
