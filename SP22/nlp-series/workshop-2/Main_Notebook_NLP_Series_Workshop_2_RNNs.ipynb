{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main Notebook: NLP Series Workshop 2: RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main Notebook: NLP Series Workshop 2: Diving Deeper into Sentiment Analysis Techniques"
      ],
      "metadata": {
        "id": "SsBNwfyb1K6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- include graphic for pipeline\n",
        "- visuals for everything\n",
        "- finish the entire noteboook\n",
        "- remove dropout, embedding (all the complicated stuff)\n",
        "- better explanations\n",
        "- need an evaluation section"
      ],
      "metadata": {
        "id": "8ci3zdSHCfHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit to this wonderful notebook: https://www.kaggle.com/code/isidronavarrooporto/hate-speech-tweet-classification"
      ],
      "metadata": {
        "id": "vWQxlVkTB13R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:red\">__DISCLAIMER__</span> : This dataset contains hateful speech and explicit content. \n",
        "\n",
        "Conventions used:\n",
        "\n",
        "❗ - Required <br>\n",
        "❓ - Question"
      ],
      "metadata": {
        "id": "NEkiowniMv54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "metadata": {
        "id": "-bQwj_cIK_nO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we'll use can be found here: https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech"
      ],
      "metadata": {
        "id": "xpeHHwzh2k1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "!mkdir twitter-sentiment\n",
        "%cd twitter-sentiment\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1tMrkYFAuzjCWjhDCJRGqVNLd4j0XrlVK')\n",
        "!unzip -q twitter-sentiment-analysis-hatred-speech.zip\n",
        "!rm twitter-sentiment-analysis-hatred-speech.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCSWL4IjNRg6",
        "outputId": "c1c7fe2a-48c4-4810-ad02-50a785279b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/twitter-sentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1tMrkYFAuzjCWjhDCJRGqVNLd4j0XrlVK\n",
            "To: /content/twitter-sentiment/twitter-sentiment-analysis-hatred-speech.zip\n",
            "100%|██████████| 1.98M/1.98M [00:00<00:00, 115MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding, Flatten, Dropout"
      ],
      "metadata": {
        "id": "9W7xI4gRPEvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = pd.read_csv(\"/content/twitter-sentiment/train.csv\")\n",
        "test_csv = pd.read_csv(\"/content/twitter-sentiment/test.csv\")"
      ],
      "metadata": {
        "id": "sgzz-Qw8Oez-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we download our data, import the relevant libraries, and load in the `.csv` files again."
      ],
      "metadata": {
        "id": "Z5VELqB2QCli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ffrI-qXX3jfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computers don't understand English! It's as simple as that. It understands numbers. So how do we turn our table of tweets into sequences of numbers?\n",
        "\n",
        "This process isn't that easy. But no worries! We will thoroughly walk you through the steps of text preprocessing with code for you toy with. \n",
        "\n",
        "Here are the steps we will take to turn our string tweets into number sequences:\n",
        "1. Clean the text by:\n",
        "  - lowercasing all text\n",
        "  - stripping the end of contractions (e.g. `what's` to `what`)\n",
        "  - breaking contractions into its components \"can't\" to \"can not\"\n",
        "  - formalizing slang (e.g. `'scuse` to `excuse`)\n",
        "  - removing special characters (that aren't an alphabetical character or number)\n",
        "  - stripping excessive white space"
      ],
      "metadata": {
        "id": "7EjBJ6rrQJdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
        "    text = text.strip(' ')\n",
        "    return text"
      ],
      "metadata": {
        "id": "ZaQS9HeY3ZTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV and drop irrelevant column.\n",
        "data = pd.read_csv(\"../twitter-sentiment/train.csv\")\n",
        "data.drop(\"id\", axis=1, inplace=True)\n",
        "\n",
        "# Run through the text cleaning pipeline twice.\n",
        "data['tweet'] = data['tweet'].map(lambda t: clean_text(t))\n",
        "data['tweet'] = data['tweet'].map(lambda t: clean_text(t))"
      ],
      "metadata": {
        "id": "14ENfhMHBzIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and convert tweets to sequence of numbers.\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['tweet'].values)\n",
        "X = tokenizer.texts_to_sequences(data['tweet'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "# Get all the labels.\n",
        "y = data[\"label\"]"
      ],
      "metadata": {
        "id": "kSTihORbCz0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=66)"
      ],
      "metadata": {
        "id": "E0Se2mTqDCA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape: \",X_train.shape)\n",
        "print(\"y_train shape: \",y_train.shape)\n",
        "print(\"X_test shape: \",X_test.shape)\n",
        "print(\"y_test shape: \",y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh6IW8vvDV3k",
        "outputId": "f50acce4-0d88-48d4-ca6e-bad5b29b179f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (27167, 39)\n",
            "y_train shape:  (27167,)\n",
            "X_test shape:  (4795, 39)\n",
            "y_test shape:  (4795,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Model"
      ],
      "metadata": {
        "id": "paW_Md2N7Wjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be building our model using tf.keras.Sequential\n",
        "\n",
        "The first layer is the encoder, which converts the text to a sequence of token indices.\n",
        "\n",
        "After the encoder is an embedding layer. An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors.\n",
        "\n",
        "These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors."
      ],
      "metadata": {
        "id": "FMiNJmjR9dab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ❓ What is an RNN?\n",
        "A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their input on the next timestep.\n"
      ],
      "metadata": {
        "id": "2pYh1zCQ-MG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using tf.keras.layers.Bidirectional wrapper with our RNN layer.\n",
        "\n",
        "This propagates the input forward and backwards through the RNN layer and then concatenates the final output."
      ],
      "metadata": {
        "id": "xPzA9Ua3_Noe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 128\n",
        "vocab_size = 3000\n",
        "simplernn_out = 64\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, embed_size, input_shape=(X_train.shape[1],)))\n",
        "  model.add(SimpleRNN(simplernn_out, activation=\"relu\", return_sequences=True))\n",
        "  model.add(SimpleRNN(simplernn_out, activation=\"relu\", return_sequences=False))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy', \n",
        "                                                                       tf.keras.metrics.Precision(), \n",
        "                                                                       tf.keras.metrics.Recall(),\n",
        "                                                                       f1_metric])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "aEtxMMhd_XMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXQeXCfAGGrv",
        "outputId": "d9abbca9-7484-45a1-851e-7672dcfeeb6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 39, 128)           384000    \n",
            "                                                                 \n",
            " simple_rnn_14 (SimpleRNN)   (None, 39, 64)            12352     \n",
            "                                                                 \n",
            " simple_rnn_15 (SimpleRNN)   (None, 64)                8256      \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,673\n",
            "Trainable params: 404,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "GMe8fFy_LRp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "history = model.fit(X_train, y_train, epochs = 7, batch_size=batch_size, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_EuX-JNFm_A",
        "outputId": "9f30df96-81ae-48a8-f748-ce6472f6b9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "680/680 [==============================] - 54s 75ms/step - loss: 0.1820 - accuracy: 0.9382 - precision_3: 0.6951 - recall_3: 0.1895 - f1_metric: 0.2018 - val_loss: 0.1438 - val_accuracy: 0.9487 - val_precision_3: 0.7222 - val_recall_3: 0.4655 - val_f1_metric: 0.4755\n",
            "Epoch 2/7\n",
            "680/680 [==============================] - 53s 79ms/step - loss: 0.1091 - accuracy: 0.9585 - precision_3: 0.7974 - recall_3: 0.5366 - f1_metric: 0.5290 - val_loss: 0.1463 - val_accuracy: 0.9503 - val_precision_3: 0.7619 - val_recall_3: 0.4501 - val_f1_metric: 0.4549\n",
            "Epoch 3/7\n",
            "680/680 [==============================] - 51s 75ms/step - loss: 0.0780 - accuracy: 0.9693 - precision_3: 0.8400 - recall_3: 0.6875 - f1_metric: 0.6444 - val_loss: 0.1696 - val_accuracy: 0.9406 - val_precision_3: 0.5867 - val_recall_3: 0.5882 - val_f1_metric: 0.5048\n",
            "Epoch 4/7\n",
            "680/680 [==============================] - 51s 76ms/step - loss: 0.0553 - accuracy: 0.9786 - precision_3: 0.8698 - recall_3: 0.8125 - f1_metric: 0.7313 - val_loss: 0.1894 - val_accuracy: 0.9538 - val_precision_3: 0.7652 - val_recall_3: 0.5166 - val_f1_metric: 0.5125\n",
            "Epoch 5/7\n",
            "680/680 [==============================] - 52s 76ms/step - loss: 0.0391 - accuracy: 0.9850 - precision_3: 0.9050 - recall_3: 0.8743 - f1_metric: 0.7932 - val_loss: 0.2728 - val_accuracy: 0.9463 - val_precision_3: 0.6581 - val_recall_3: 0.5269 - val_f1_metric: 0.5026\n",
            "Epoch 6/7\n",
            "680/680 [==============================] - 51s 75ms/step - loss: 0.0262 - accuracy: 0.9910 - precision_3: 0.9425 - recall_3: 0.9262 - f1_metric: 0.8269 - val_loss: 0.2894 - val_accuracy: 0.9450 - val_precision_3: 0.6361 - val_recall_3: 0.5499 - val_f1_metric: 0.5044\n",
            "Epoch 7/7\n",
            "680/680 [==============================] - 52s 76ms/step - loss: 0.0204 - accuracy: 0.9926 - precision_3: 0.9565 - recall_3: 0.9362 - f1_metric: 0.8293 - val_loss: 0.3302 - val_accuracy: 0.9466 - val_precision_3: 0.6613 - val_recall_3: 0.5294 - val_f1_metric: 0.5116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yx7gFek4M6dv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}