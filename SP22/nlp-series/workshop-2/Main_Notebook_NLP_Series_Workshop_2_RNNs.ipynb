{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main Notebook: NLP Series Workshop 2: RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main Notebook: NLP Series Workshop 2: Diving Deeper into Sentiment Analysis Techniques"
      ],
      "metadata": {
        "id": "SsBNwfyb1K6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- include graphic for pipeline\n",
        "- visuals for everything\n",
        "- finish the entire noteboook\n",
        "- remove dropout, embedding (all the complicated stuff)\n",
        "- better explanations\n",
        "  - Vincent: I explained everything up to the modeling part.\n",
        "- need an evaluation section"
      ],
      "metadata": {
        "id": "8ci3zdSHCfHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit to this wonderful notebook: https://www.kaggle.com/code/isidronavarrooporto/hate-speech-tweet-classification"
      ],
      "metadata": {
        "id": "vWQxlVkTB13R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:red\">__DISCLAIMER__</span> : This dataset contains hateful speech and explicit content. \n",
        "\n",
        "Conventions used:\n",
        "\n",
        "❗ - Required <br>\n",
        "❓ - Question"
      ],
      "metadata": {
        "id": "NEkiowniMv54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "metadata": {
        "id": "-bQwj_cIK_nO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we'll use can be found here: https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech"
      ],
      "metadata": {
        "id": "xpeHHwzh2k1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "!mkdir twitter-sentiment\n",
        "%cd twitter-sentiment\n",
        "gdown.download('https://drive.google.com/uc?export=download&id=1tMrkYFAuzjCWjhDCJRGqVNLd4j0XrlVK')\n",
        "!unzip -q twitter-sentiment-analysis-hatred-speech.zip\n",
        "!rm twitter-sentiment-analysis-hatred-speech.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCSWL4IjNRg6",
        "outputId": "551f3ec0-8254-45d3-d57c-42358bbadf40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/twitter-sentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1tMrkYFAuzjCWjhDCJRGqVNLd4j0XrlVK\n",
            "To: /content/twitter-sentiment/twitter-sentiment-analysis-hatred-speech.zip\n",
            "100%|██████████| 1.98M/1.98M [00:00<00:00, 162MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding, Flatten, Dropout"
      ],
      "metadata": {
        "id": "9W7xI4gRPEvp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = pd.read_csv(\"/content/twitter-sentiment/train.csv\")\n",
        "test_csv = pd.read_csv(\"/content/twitter-sentiment/test.csv\")"
      ],
      "metadata": {
        "id": "My9C4SiTZY36"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we download our data, import the relevant libraries, and load in the `.csv` files again.\n",
        "\n",
        "Let's take a quick look at the train data again just for a refresher!"
      ],
      "metadata": {
        "id": "Z5VELqB2QCli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "H_6x39pdfFSV",
        "outputId": "b3b0680a-6500-45f6-809f-198335c15528"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  label                                              tweet\n",
              "0          1      0   @user when a father is dysfunctional and is s...\n",
              "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2          3      0                                bihday your majesty\n",
              "3          4      0  #model   i love u take with u all the time in ...\n",
              "4          5      0             factsguide: society now    #motivation\n",
              "...      ...    ...                                                ...\n",
              "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
              "31958  31959      0    to see nina turner on the airwaves trying to...\n",
              "31959  31960      0  listening to sad songs on a monday morning otw...\n",
              "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
              "31961  31962      0                   thank you @user for you follow  \n",
              "\n",
              "[31962 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e66ba73-28b3-4848-8cf7-c2f98a1bc81b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>31958</td>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>31959</td>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>31960</td>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>31961</td>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>31962</td>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e66ba73-28b3-4848-8cf7-c2f98a1bc81b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e66ba73-28b3-4848-8cf7-c2f98a1bc81b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e66ba73-28b3-4848-8cf7-c2f98a1bc81b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ffrI-qXX3jfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computers don't understand English! It's as simple as that. It understands numbers. So how do we turn our table of tweets into sequences of numbers?\n",
        "\n",
        "This process isn't that easy. But no worries! We will thoroughly walk you through the steps of text preprocessing with code for you toy with. \n",
        "\n",
        "Here are the steps we will take to turn our string tweets into number sequences:\n",
        "1. Clean the text by:\n",
        "  - lowercasing all text\n",
        "  - stripping the end of contractions (e.g. `what's` to `what`)\n",
        "  - breaking contractions into its components \"can't\" to \"can not\"\n",
        "  - formalizing slang (e.g. `'scuse` to `excuse`)\n",
        "  - removing special characters (that aren't an alphabetical character or number)\n",
        "    - this includes punctuation!\n",
        "  - stripping excessive white space"
      ],
      "metadata": {
        "id": "7EjBJ6rrQJdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
        "    text = text.strip(' ')\n",
        "    return text"
      ],
      "metadata": {
        "id": "ZaQS9HeY3ZTu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can remove the irrelevant `id` column and run that function for cleaning tweets we just defined through all the tweets in the dataset. We run it twice so that the data is extra tidy!\n",
        "\n",
        "__Note__: Even though we have a function that cleans up all the textual mess, it is not comprehensive nor perfect. There will always be some small textual problems (e.g. maybe you couldn't break all the contractions up). But, for the purposes of our simple model, this is perfectly fine!"
      ],
      "metadata": {
        "id": "14u3pfA9ZHTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop irrelevant column.\n",
        "train_csv.drop(\"id\", axis=1, inplace=True)\n",
        "\n",
        "# Run through the text cleaning pipeline twice.\n",
        "train_csv['tweet'] = train_csv['tweet'].map(lambda t: clean_text(t))\n",
        "train_csv['tweet'] = train_csv['tweet'].map(lambda t: clean_text(t))"
      ],
      "metadata": {
        "id": "14ENfhMHBzIP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bKqhvvxnfXn7",
        "outputId": "1430f160-477c-4cc8-d139-9ac56264238f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                              tweet\n",
              "0          0  user when a father is dysfunctional and is so ...\n",
              "1          0  user user thanks for lyft credit i can not use...\n",
              "2          0                                bihday your majesty\n",
              "3          0      model i love u take with u all the time in ur\n",
              "4          0                  factsguide society now motivation\n",
              "...      ...                                                ...\n",
              "31957      0                            ate user isz that youuu\n",
              "31958      0  to see nina turner on the airwaves trying to w...\n",
              "31959      0  listening to sad songs on a monday morning otw...\n",
              "31960      1  user sikh temple vandalised in in calgary wso ...\n",
              "31961      0                      thank you user for you follow\n",
              "\n",
              "[31962 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8df0385-1f7a-4478-8d45-854ef5da28c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>user when a father is dysfunctional and is so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>user user thanks for lyft credit i can not use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>model i love u take with u all the time in ur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate user isz that youuu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>user sikh temple vandalised in in calgary wso ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you user for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8df0385-1f7a-4478-8d45-854ef5da28c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8df0385-1f7a-4478-8d45-854ef5da28c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8df0385-1f7a-4478-8d45-854ef5da28c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice we dropped the `id` column and also the text is a lot more readable. \n",
        "\n",
        "Basically, we now have a train dataset of tweets that solely consist of lowercase words, no punctuations, no special characters, no weird spacing, etc!"
      ],
      "metadata": {
        "id": "b6TVN2V0caL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define a tokenizer.\n",
        "\n",
        "❓: What is a __tokenizer__?\n",
        "\n",
        "> __tokenizer__ : an NLP technique that converts sentences (text, more generally) to a sequence of tokens; in this case, we want the model to train on this data so our tokens take the form of numbers!\n",
        "\n",
        "Essentially, a tokenizer will build a __vocabulary__ which is a dictionary like below.\n",
        "\n",
        "```py\n",
        "vocabulary = {\n",
        "  0: <e> (end token),\n",
        "  1: <s> (start token),\n",
        "  2: <UNK> (unknown token),\n",
        "  3: the,\n",
        "  4: a,\n",
        "  5: how,\n",
        "  ...\n",
        "}\n",
        "```\n",
        "\n",
        "We see the tokenizer's vocabulary usually reserves the first 3 spots for special tokens that denote when a sentence ends, starts, and unknown characters.\n",
        "\n",
        "Right below, we have a tokenizer defined with a max vocabulary size of 2000. The `split` parameter simply says that each of our clean and tidy tweets are sentences that are separated by spaces!"
      ],
      "metadata": {
        "id": "SViVfJ0Zfmvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tokenizer.\n",
        "vocabulary_size = 2000\n",
        "tokenizer = Tokenizer(num_words=vocabulary_size, split=' ')"
      ],
      "metadata": {
        "id": "kSTihORbCz0R"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv['tweet'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txBXR44tkTyf",
        "outputId": "c345f274-0db7-4e5f-e34c-e6f776f33299"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction run',\n",
              "       'user user thanks for lyft credit i can not use cause they do not offer wheelchair vans in pdx disapointed getthanked',\n",
              "       'bihday your majesty', ...,\n",
              "       'listening to sad songs on a monday morning otw to work is sad',\n",
              "       'user sikh temple vandalised in in calgary wso condemns act',\n",
              "       'thank you user for you follow'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we fit this tokenizer to the text with the convenient `fit_on_texts` method. \n",
        "\n",
        "In case you're curious what `train_csv['tweet'].values` is:\n",
        "\n",
        "```py\n",
        "[\n",
        "  'user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction run',\n",
        "  'user user thanks for lyft credit i can not use cause they do not offer wheelchair vans in pdx disapointed getthanked',\n",
        "  'bihday your majesty',\n",
        "  ...\n",
        "]\n",
        "```\n",
        "\n",
        "Essentially the `fit_on_texts` method takes in a list of clean, tidy strings. It does not output anything, instead the tokenizer will build the vocabulary we specified above with this method."
      ],
      "metadata": {
        "id": "qhew1kKsjdzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the tokenizer on all the train tweets to establish a vocabulary. \n",
        "tokenizer.fit_on_texts(train_csv['tweet'].values)"
      ],
      "metadata": {
        "id": "0AXKnb0CjqAg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afterwards, our tokenizer will have a vocabulary. With this vocabulary, it will convert the list of clean, tidy tweets into numbers.\n",
        "\n",
        "If you're curious what `X` looks like:\n",
        "\n",
        "```py\n",
        "[[1, 37, 5, 71, 10, 7, 10, 26, 73, 95, 250, 255, 95, 456],\n",
        " [1, 1, 169, 9, 4, 35, 14, 439, 649, 62, 27, 14, 1522, 8],\n",
        " [57, 31],\n",
        " [141, 4, 15, 38, 75, 19, 38, 24, 2, 41, 8, 111],\n",
        " [1480, 47, 293],\n",
        " [74, 74, 1034, 705, 7, 260, 706, 243, 62, 366, 7, 189, 37, 62, 54, 83],\n",
        " [1, 112, 1, 1, 1, 1, 1, 1, 1],\n",
        " ...\n",
        "]\n",
        "```\n",
        "\n",
        "In short, it took our list of clean, tidy tweets into numbers where each number corresponds to a word in the vocabulary."
      ],
      "metadata": {
        "id": "yViUbH4MkqWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using this vocabulary, the tokenizer converts each tweet into a sequence of numbers\n",
        "# where each number corresponds to a word in the vocabulary. \n",
        "X = tokenizer.texts_to_sequences(train_csv['tweet'].values)"
      ],
      "metadata": {
        "id": "0FwmS6xmjc4m"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that these tweets are mostly of different lengths! Models don't like that. So we basically find a point to cut off long tweets, and any tweet shorter than that cut off point will be padded with 0s. That's what `pad_sequences` does!\n",
        "\n",
        "If you're curious what `X` looks like after running the below cell:\n",
        "\n",
        "```py\n",
        "[[   0,    0,    0, ...,  255,   95,  456],\n",
        " [   0,    0,    0, ...,   14, 1522,    8],\n",
        " [   0,    0,    0, ...,    0,   57,   31],\n",
        " ...,\n",
        " [   0,    0,    0, ...,   76,   10,  120],\n",
        " [   0,    0,    0, ..., 1608, 1609,  672],\n",
        " [   0,    0,    0, ...,    9,    6,  152]\n",
        "]\n",
        "```\n",
        "\n",
        "Notice how it is a rectangular matrix now."
      ],
      "metadata": {
        "id": "WsOuJWxgllfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences.\n",
        "X = pad_sequences(X)"
      ],
      "metadata": {
        "id": "hl6Xw9wAlG6F"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we will also get labels for all the tweets.\n",
        "\n",
        "If you're curious what `y` looks like:\n",
        "\n",
        "```py\n",
        "[\n",
        "  0,\n",
        "  1,\n",
        "  0,\n",
        "  1,\n",
        "  1,\n",
        "  ...\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "Ur43vFvMmKQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the labels.\n",
        "y = train_csv[\"label\"]"
      ],
      "metadata": {
        "id": "SoUn-WVAlH-V"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we now have a list of labels and a rectangular matrix where each row is a tweet and all tweets are not only clean and tidy but in their numeric form (tokenized form). We will apply the train and test split from before to partition the data.\n",
        "\n",
        "__Note__: remember we have been working with the train data all this time, so we are actually splitting the train dataset."
      ],
      "metadata": {
        "id": "5CLZ3V0UmX1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=66)"
      ],
      "metadata": {
        "id": "E0Se2mTqDCA7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"y_test shape: \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh6IW8vvDV3k",
        "outputId": "acda2bfc-1fd7-46bc-c0fb-ce648331c0c5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (27167, 39)\n",
            "y_train shape:  (27167,)\n",
            "X_test shape:  (4795, 39)\n",
            "y_test shape:  (4795,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Model"
      ],
      "metadata": {
        "id": "paW_Md2N7Wjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be building our model using tf.keras.Sequential\n",
        "\n",
        "The first layer is the encoder, which converts the text to a sequence of token indices.\n",
        "\n",
        "After the encoder is an embedding layer. An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors.\n",
        "\n",
        "These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors."
      ],
      "metadata": {
        "id": "FMiNJmjR9dab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ❓ What is an RNN?\n",
        "A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their input on the next timestep.\n"
      ],
      "metadata": {
        "id": "2pYh1zCQ-MG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using tf.keras.layers.Bidirectional wrapper with our RNN layer.\n",
        "\n",
        "This propagates the input forward and backwards through the RNN layer and then concatenates the final output."
      ],
      "metadata": {
        "id": "xPzA9Ua3_Noe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 128\n",
        "vocab_size = 3000\n",
        "simplernn_out = 64\n",
        "\n",
        "def f1_metric(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, embed_size, input_shape=(X_train.shape[1],)))\n",
        "  model.add(SimpleRNN(simplernn_out, activation=\"relu\", return_sequences=True))\n",
        "  model.add(SimpleRNN(simplernn_out, activation=\"relu\", return_sequences=False))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy', \n",
        "                                                                       tf.keras.metrics.Precision(), \n",
        "                                                                       tf.keras.metrics.Recall(),\n",
        "                                                                       f1_metric])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "aEtxMMhd_XMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXQeXCfAGGrv",
        "outputId": "d9abbca9-7484-45a1-851e-7672dcfeeb6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 39, 128)           384000    \n",
            "                                                                 \n",
            " simple_rnn_14 (SimpleRNN)   (None, 39, 64)            12352     \n",
            "                                                                 \n",
            " simple_rnn_15 (SimpleRNN)   (None, 64)                8256      \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,673\n",
            "Trainable params: 404,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "GMe8fFy_LRp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "history = model.fit(X_train, y_train, epochs = 7, batch_size=batch_size, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_EuX-JNFm_A",
        "outputId": "9f30df96-81ae-48a8-f748-ce6472f6b9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "680/680 [==============================] - 54s 75ms/step - loss: 0.1820 - accuracy: 0.9382 - precision_3: 0.6951 - recall_3: 0.1895 - f1_metric: 0.2018 - val_loss: 0.1438 - val_accuracy: 0.9487 - val_precision_3: 0.7222 - val_recall_3: 0.4655 - val_f1_metric: 0.4755\n",
            "Epoch 2/7\n",
            "680/680 [==============================] - 53s 79ms/step - loss: 0.1091 - accuracy: 0.9585 - precision_3: 0.7974 - recall_3: 0.5366 - f1_metric: 0.5290 - val_loss: 0.1463 - val_accuracy: 0.9503 - val_precision_3: 0.7619 - val_recall_3: 0.4501 - val_f1_metric: 0.4549\n",
            "Epoch 3/7\n",
            "680/680 [==============================] - 51s 75ms/step - loss: 0.0780 - accuracy: 0.9693 - precision_3: 0.8400 - recall_3: 0.6875 - f1_metric: 0.6444 - val_loss: 0.1696 - val_accuracy: 0.9406 - val_precision_3: 0.5867 - val_recall_3: 0.5882 - val_f1_metric: 0.5048\n",
            "Epoch 4/7\n",
            "680/680 [==============================] - 51s 76ms/step - loss: 0.0553 - accuracy: 0.9786 - precision_3: 0.8698 - recall_3: 0.8125 - f1_metric: 0.7313 - val_loss: 0.1894 - val_accuracy: 0.9538 - val_precision_3: 0.7652 - val_recall_3: 0.5166 - val_f1_metric: 0.5125\n",
            "Epoch 5/7\n",
            "680/680 [==============================] - 52s 76ms/step - loss: 0.0391 - accuracy: 0.9850 - precision_3: 0.9050 - recall_3: 0.8743 - f1_metric: 0.7932 - val_loss: 0.2728 - val_accuracy: 0.9463 - val_precision_3: 0.6581 - val_recall_3: 0.5269 - val_f1_metric: 0.5026\n",
            "Epoch 6/7\n",
            "680/680 [==============================] - 51s 75ms/step - loss: 0.0262 - accuracy: 0.9910 - precision_3: 0.9425 - recall_3: 0.9262 - f1_metric: 0.8269 - val_loss: 0.2894 - val_accuracy: 0.9450 - val_precision_3: 0.6361 - val_recall_3: 0.5499 - val_f1_metric: 0.5044\n",
            "Epoch 7/7\n",
            "680/680 [==============================] - 52s 76ms/step - loss: 0.0204 - accuracy: 0.9926 - precision_3: 0.9565 - recall_3: 0.9362 - f1_metric: 0.8293 - val_loss: 0.3302 - val_accuracy: 0.9466 - val_precision_3: 0.6613 - val_recall_3: 0.5294 - val_f1_metric: 0.5116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yx7gFek4M6dv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}