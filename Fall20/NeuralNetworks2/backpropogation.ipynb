{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient of loss function: L'(W1, b1, W2, b2).\n",
    "def L_prime(X, Y, W1, b1, W2, b2):\n",
    "    \"\"\" L'(W,b) function. \n",
    "    X:  Feature matrix.    Shape: [n,2].\n",
    "    Y:  Label vector.      Shape: [n,1].\n",
    "    W1: Weight matrix W1.  Shape: [2,3].\n",
    "    b1: Bias vector b1.    Shape: [3,1].\n",
    "    W2: Weight matrix W2.  Shape: [3,1].\n",
    "    b2: Bias vector b2.    Shape: [1,1].\n",
    "    Return the gradients: dL/dW1 (Shape: [2,3]), dL/db1 (Shape: [3,1]),\n",
    "                          dL/dW2 (Shape: [3,1]), dL/db2 (Shape: [1,1]).\n",
    "    \"\"\"\n",
    "    # Get dimensions.\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Calculate feed-forward values.\n",
    "\n",
    "    H = sigmoid(W1.T.dot(X.T) + b1).T                          # Shape: [n, 3].\n",
    "    P = Y*(W2.T.dot(H.T)+b2).T                           # Shape: [n, 1].\n",
    "#     print(P.shape)\n",
    "    # Calculate the gradients: dL/dW1, dL/db1, dL/dW2, dL/db2.\n",
    "    dL_by_dW2 = H.T.dot((P-1)*Y)                            # Shape: [3,1].\n",
    "    \n",
    "#     dL_by_db2 =  (P-1).T.dot(Y)                           # Shape: [1,1].\n",
    "    dL_by_db2 = np.ones((n,1)).T.dot((P-1)*Y)\n",
    "    \n",
    "#     print(W2.shape)\n",
    "    dL_by_dH  = ((P-1)*Y).dot(W2.T)                           # Shape: [n,3].\n",
    "    dL_by_dW1  = X.T.dot(dL_by_dH*H*(1-H))                   # Shape: [2,3].\n",
    "#     print(dL_by_dW1.shape)\n",
    "    dL_by_db1  = (dL_by_dH*H*(1-H)).T.dot(np.ones((n,1)))                        # Shape: [3,1].\n",
    "#     print(dL_by_db1.shape)\n",
    "    return dL_by_dW1, dL_by_db1, dL_by_dW2, dL_by_db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def L(X, Y, W1, b1, W2, b2):\n",
    "    \"\"\" L(W,b) function. \n",
    "    X:  Feature matrix.    Shape: [n,2].\n",
    "    Y:  Label vector.      Shape: [n,1].\n",
    "    W1: Weight matrix W1.  Shape: [2,3].\n",
    "    b1: Bias vector b1.    Shape: [3,1].\n",
    "    W2: Weight matrix W2.  Shape: [3,1].\n",
    "    b2: Bias vector b2.    Shape: [1,1].\n",
    "    Return the loss.       Shape: Scalar.\n",
    "    \"\"\"\n",
    "    # Get dimensions.\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Calculate feed-forward values.\n",
    "#     print(X.shape)\n",
    "    \n",
    "    H = sigmoid(W1.T.dot(X.T) + b1).T                             # Shape: [n, 3].\n",
    "#     print(H.shape)\n",
    "#     print(W2.T.dot(H.T).shape)\n",
    "    P = sigmoid(Y*(W2.T.dot(H.T)+b2).T)                             # Shape: [n, 1].\n",
    "    \n",
    "#     print((W2.T.dot(H.T)+b2).shape)\n",
    "#     print(P.shape)\n",
    "    # Get the loss.\n",
    "    L =    -np.sum(np.log(P))                        # Shape: Scalar.\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets generate some data using a function mapping from R^2 -> R^1 (2d coordinates to scalar values)\n",
    "def generate_data():\n",
    "    \n",
    "    # generates 1000 ordered data points from 0 to 1 with a bit of noise using random.uniform\n",
    "    def generate_linear_noisy():\n",
    "        return np.linspace(0, 1, num=1000) + np.random.uniform(-0.05, 0.05, (1000,))\n",
    "    \n",
    "    X_train = np.array([generate_linear_noisy(), generate_linear_noisy()]).T\n",
    "    \n",
    "    # the function modeled here is F(x, y) -> x / 2 + y / 2\n",
    "    Y_train = (X_train[:,0] * 0.5 + X_train[:,1] * 0.5).reshape(1000, 1)\n",
    "    return X_train, Y_train\n",
    "X_train, Y_train = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04739148  0.03284548]\n",
      " [-0.01272119 -0.0220772 ]\n",
      " [ 0.0338837  -0.03660984]\n",
      " ...\n",
      " [ 1.04537137  1.00214967]\n",
      " [ 1.01571349  0.97313234]\n",
      " [ 0.97557795  0.9906448 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "# supposed to find where loss is minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:      0 L: 498.674 norm:0.055257\n",
      "i:    500 L: 406.410 norm:0.002239\n",
      "i:   1000 L: 403.164 norm:0.003733\n",
      "i:   1500 L: 396.925 norm:0.005403\n",
      "i:   2000 L: 386.843 norm:0.006417\n",
      "i:   2500 L: 374.793 norm:0.005971\n",
      "i:   3000 L: 364.575 norm:0.004444\n",
      "i:   3500 L: 357.869 norm:0.002940\n",
      "i:   4000 L: 353.861 norm:0.002231\n",
      "i:   4500 L: 351.339 norm:0.001968\n",
      "i:   5000 L: 349.543 norm:0.001782\n",
      "i:   5500 L: 348.109 norm:0.001648\n",
      "i:   6000 L: 346.888 norm:0.001552\n",
      "i:   6500 L: 345.816 norm:0.001480\n",
      "i:   7000 L: 344.861 norm:0.001408\n",
      "i:   7500 L: 344.005 norm:0.001337\n",
      "i:   8000 L: 343.233 norm:0.001268\n",
      "i:   8500 L: 342.533 norm:0.001202\n",
      "i:   9000 L: 341.897 norm:0.001137\n",
      "i:   9500 L: 341.317 norm:0.001076\n",
      "i:  10000 L: 340.786 norm:0.001018\n",
      "i:  10500 L: 340.299 norm:0.000964\n",
      "i:  11000 L: 339.850 norm:0.000914\n",
      "i:  11500 L: 339.436 norm:0.000873\n",
      "i:  12000 L: 339.053 norm:0.000836\n",
      "i:  12500 L: 338.697 norm:0.000802\n",
      "i:  13000 L: 338.366 norm:0.000770\n",
      "i:  13500 L: 338.057 norm:0.000740\n",
      "i:  14000 L: 337.767 norm:0.000712\n",
      "i:  14500 L: 337.495 norm:0.000686\n",
      "i:  15000 L: 337.239 norm:0.000661\n",
      "i:  15500 L: 336.997 norm:0.000638\n",
      "i:  16000 L: 336.768 norm:0.000616\n",
      "i:  16500 L: 336.551 norm:0.000596\n",
      "i:  17000 L: 336.345 norm:0.000578\n",
      "i:  17500 L: 336.148 norm:0.000561\n",
      "i:  18000 L: 335.961 norm:0.000546\n",
      "i:  18500 L: 335.782 norm:0.000531\n",
      "i:  19000 L: 335.610 norm:0.000517\n",
      "i:  19500 L: 335.446 norm:0.000503\n",
      "i:  20000 L: 335.288 norm:0.000490\n",
      "i:  20500 L: 335.137 norm:0.000477\n",
      "i:  21000 L: 334.991 norm:0.000465\n",
      "i:  21500 L: 334.850 norm:0.000453\n",
      "i:  22000 L: 334.714 norm:0.000442\n",
      "i:  22500 L: 334.583 norm:0.000431\n",
      "i:  23000 L: 334.456 norm:0.000421\n",
      "i:  23500 L: 334.333 norm:0.000410\n",
      "i:  24000 L: 334.214 norm:0.000401\n",
      "i:  24500 L: 334.099 norm:0.000391\n",
      "i:  25000 L: 333.987 norm:0.000382\n",
      "i:  25500 L: 333.879 norm:0.000374\n",
      "i:  26000 L: 333.773 norm:0.000366\n",
      "i:  26500 L: 333.670 norm:0.000359\n",
      "i:  27000 L: 333.570 norm:0.000353\n",
      "i:  27500 L: 333.472 norm:0.000348\n",
      "i:  28000 L: 333.377 norm:0.000343\n",
      "i:  28500 L: 333.284 norm:0.000338\n",
      "i:  29000 L: 333.194 norm:0.000335\n",
      "i:  29500 L: 333.105 norm:0.000332\n",
      "i:  30000 L: 333.018 norm:0.000330\n",
      "i:  30500 L: 332.934 norm:0.000329\n",
      "i:  31000 L: 332.851 norm:0.000328\n",
      "i:  31500 L: 332.769 norm:0.000326\n",
      "i:  32000 L: 332.690 norm:0.000325\n",
      "i:  32500 L: 332.612 norm:0.000324\n",
      "i:  33000 L: 332.535 norm:0.000323\n",
      "i:  33500 L: 332.460 norm:0.000322\n",
      "i:  34000 L: 332.386 norm:0.000322\n",
      "i:  34500 L: 332.313 norm:0.000321\n",
      "i:  35000 L: 332.242 norm:0.000320\n",
      "i:  35500 L: 332.172 norm:0.000319\n",
      "i:  36000 L: 332.103 norm:0.000319\n",
      "i:  36500 L: 332.035 norm:0.000318\n",
      "i:  37000 L: 331.968 norm:0.000318\n",
      "i:  37500 L: 331.902 norm:0.000317\n",
      "i:  38000 L: 331.838 norm:0.000317\n",
      "i:  38500 L: 331.774 norm:0.000316\n",
      "i:  39000 L: 331.711 norm:0.000316\n",
      "i:  39500 L: 331.649 norm:0.000315\n",
      "i:  40000 L: 331.588 norm:0.000315\n",
      "i:  40500 L: 331.528 norm:0.000314\n",
      "i:  41000 L: 331.468 norm:0.000314\n",
      "i:  41500 L: 331.410 norm:0.000313\n",
      "i:  42000 L: 331.352 norm:0.000313\n",
      "i:  42500 L: 331.295 norm:0.000312\n",
      "i:  43000 L: 331.238 norm:0.000311\n",
      "i:  43500 L: 331.183 norm:0.000311\n",
      "i:  44000 L: 331.128 norm:0.000310\n",
      "i:  44500 L: 331.074 norm:0.000309\n",
      "i:  45000 L: 331.020 norm:0.000308\n",
      "i:  45500 L: 330.967 norm:0.000307\n",
      "i:  46000 L: 330.915 norm:0.000306\n",
      "i:  46500 L: 330.864 norm:0.000305\n",
      "i:  47000 L: 330.813 norm:0.000304\n",
      "i:  47500 L: 330.763 norm:0.000302\n",
      "i:  48000 L: 330.713 norm:0.000301\n",
      "i:  48500 L: 330.664 norm:0.000300\n",
      "i:  49000 L: 330.616 norm:0.000298\n",
      "i:  49500 L: 330.568 norm:0.000296\n",
      "i:  50000 L: 330.521 norm:0.000295\n",
      "i:  50500 L: 330.475 norm:0.000293\n",
      "i:  51000 L: 330.429 norm:0.000291\n",
      "i:  51500 L: 330.384 norm:0.000289\n",
      "i:  52000 L: 330.339 norm:0.000287\n",
      "i:  52500 L: 330.295 norm:0.000285\n",
      "i:  53000 L: 330.251 norm:0.000283\n",
      "i:  53500 L: 330.208 norm:0.000281\n",
      "i:  54000 L: 330.166 norm:0.000279\n",
      "i:  54500 L: 330.124 norm:0.000277\n",
      "i:  55000 L: 330.083 norm:0.000274\n",
      "i:  55500 L: 330.042 norm:0.000272\n",
      "i:  56000 L: 330.001 norm:0.000270\n",
      "i:  56500 L: 329.962 norm:0.000267\n",
      "i:  57000 L: 329.922 norm:0.000265\n",
      "i:  57500 L: 329.883 norm:0.000262\n",
      "i:  58000 L: 329.845 norm:0.000260\n",
      "i:  58500 L: 329.807 norm:0.000257\n",
      "i:  59000 L: 329.770 norm:0.000255\n",
      "i:  59500 L: 329.733 norm:0.000253\n",
      "i:  60000 L: 329.696 norm:0.000250\n",
      "i:  60500 L: 329.660 norm:0.000248\n",
      "i:  61000 L: 329.625 norm:0.000245\n",
      "i:  61500 L: 329.589 norm:0.000243\n",
      "i:  62000 L: 329.555 norm:0.000240\n",
      "i:  62500 L: 329.520 norm:0.000238\n",
      "i:  63000 L: 329.486 norm:0.000235\n",
      "i:  63500 L: 329.453 norm:0.000233\n",
      "i:  64000 L: 329.419 norm:0.000231\n",
      "i:  64500 L: 329.387 norm:0.000228\n",
      "i:  65000 L: 329.354 norm:0.000226\n",
      "i:  65500 L: 329.322 norm:0.000224\n",
      "i:  66000 L: 329.290 norm:0.000221\n",
      "i:  66500 L: 329.259 norm:0.000219\n",
      "i:  67000 L: 329.228 norm:0.000217\n",
      "i:  67500 L: 329.197 norm:0.000215\n",
      "i:  68000 L: 329.167 norm:0.000212\n",
      "i:  68500 L: 329.137 norm:0.000210\n",
      "i:  69000 L: 329.107 norm:0.000208\n",
      "i:  69500 L: 329.078 norm:0.000206\n",
      "i:  70000 L: 329.048 norm:0.000204\n",
      "i:  70500 L: 329.020 norm:0.000202\n",
      "i:  71000 L: 328.991 norm:0.000200\n",
      "i:  71500 L: 328.963 norm:0.000199\n",
      "i:  72000 L: 328.935 norm:0.000197\n",
      "i:  72500 L: 328.907 norm:0.000196\n",
      "i:  73000 L: 328.880 norm:0.000194\n",
      "i:  73500 L: 328.853 norm:0.000193\n",
      "i:  74000 L: 328.826 norm:0.000191\n",
      "i:  74500 L: 328.799 norm:0.000190\n",
      "i:  75000 L: 328.773 norm:0.000188\n",
      "i:  75500 L: 328.747 norm:0.000187\n",
      "i:  76000 L: 328.721 norm:0.000185\n",
      "i:  76500 L: 328.696 norm:0.000184\n",
      "i:  77000 L: 328.670 norm:0.000183\n",
      "i:  77500 L: 328.645 norm:0.000181\n",
      "i:  78000 L: 328.621 norm:0.000180\n",
      "i:  78500 L: 328.596 norm:0.000178\n",
      "i:  79000 L: 328.572 norm:0.000177\n",
      "i:  79500 L: 328.548 norm:0.000176\n",
      "i:  80000 L: 328.524 norm:0.000175\n",
      "i:  80500 L: 328.500 norm:0.000173\n",
      "i:  81000 L: 328.477 norm:0.000172\n",
      "i:  81500 L: 328.453 norm:0.000171\n",
      "i:  82000 L: 328.430 norm:0.000170\n",
      "i:  82500 L: 328.407 norm:0.000168\n",
      "i:  83000 L: 328.385 norm:0.000167\n",
      "i:  83500 L: 328.362 norm:0.000166\n",
      "i:  84000 L: 328.340 norm:0.000165\n",
      "i:  84500 L: 328.318 norm:0.000164\n",
      "i:  85000 L: 328.296 norm:0.000163\n",
      "i:  85500 L: 328.275 norm:0.000162\n",
      "i:  86000 L: 328.253 norm:0.000161\n",
      "i:  86500 L: 328.232 norm:0.000160\n",
      "i:  87000 L: 328.211 norm:0.000159\n",
      "i:  87500 L: 328.190 norm:0.000157\n",
      "i:  88000 L: 328.170 norm:0.000156\n",
      "i:  88500 L: 328.149 norm:0.000155\n",
      "i:  89000 L: 328.129 norm:0.000154\n",
      "i:  89500 L: 328.109 norm:0.000154\n",
      "i:  90000 L: 328.089 norm:0.000153\n",
      "i:  90500 L: 328.069 norm:0.000152\n",
      "i:  91000 L: 328.049 norm:0.000151\n",
      "i:  91500 L: 328.030 norm:0.000150\n",
      "i:  92000 L: 328.011 norm:0.000150\n",
      "i:  92500 L: 327.991 norm:0.000149\n",
      "i:  93000 L: 327.973 norm:0.000148\n",
      "i:  93500 L: 327.954 norm:0.000148\n",
      "i:  94000 L: 327.935 norm:0.000147\n",
      "i:  94500 L: 327.917 norm:0.000146\n",
      "i:  95000 L: 327.898 norm:0.000146\n",
      "i:  95500 L: 327.880 norm:0.000145\n",
      "i:  96000 L: 327.862 norm:0.000144\n",
      "i:  96500 L: 327.844 norm:0.000144\n",
      "i:  97000 L: 327.826 norm:0.000143\n",
      "i:  97500 L: 327.809 norm:0.000142\n",
      "i:  98000 L: 327.791 norm:0.000142\n",
      "i:  98500 L: 327.774 norm:0.000141\n",
      "i:  99000 L: 327.757 norm:0.000141\n",
      "i:  99500 L: 327.740 norm:0.000140\n",
      "i: 100000 L: 327.723 norm:0.000139\n",
      "i: 100500 L: 327.706 norm:0.000139\n",
      "i: 101000 L: 327.690 norm:0.000138\n",
      "i: 101500 L: 327.673 norm:0.000137\n",
      "i: 102000 L: 327.657 norm:0.000137\n",
      "i: 102500 L: 327.641 norm:0.000136\n",
      "i: 103000 L: 327.625 norm:0.000136\n",
      "i: 103500 L: 327.609 norm:0.000135\n",
      "i: 104000 L: 327.593 norm:0.000135\n",
      "i: 104500 L: 327.577 norm:0.000134\n",
      "i: 105000 L: 327.561 norm:0.000134\n",
      "i: 105500 L: 327.546 norm:0.000133\n",
      "i: 106000 L: 327.531 norm:0.000132\n",
      "i: 106500 L: 327.515 norm:0.000132\n",
      "i: 107000 L: 327.500 norm:0.000131\n",
      "i: 107500 L: 327.485 norm:0.000131\n",
      "i: 108000 L: 327.470 norm:0.000130\n",
      "i: 108500 L: 327.456 norm:0.000130\n",
      "i: 109000 L: 327.441 norm:0.000129\n",
      "i: 109500 L: 327.426 norm:0.000129\n",
      "i: 110000 L: 327.412 norm:0.000128\n",
      "i: 110500 L: 327.397 norm:0.000128\n",
      "i: 111000 L: 327.383 norm:0.000127\n",
      "i: 111500 L: 327.369 norm:0.000127\n",
      "i: 112000 L: 327.355 norm:0.000126\n",
      "i: 112500 L: 327.341 norm:0.000126\n",
      "i: 113000 L: 327.327 norm:0.000125\n",
      "i: 113500 L: 327.314 norm:0.000125\n",
      "i: 114000 L: 327.300 norm:0.000124\n",
      "i: 114500 L: 327.286 norm:0.000124\n",
      "i: 115000 L: 327.273 norm:0.000123\n",
      "i: 115500 L: 327.260 norm:0.000123\n",
      "i: 116000 L: 327.246 norm:0.000123\n",
      "i: 116500 L: 327.233 norm:0.000122\n",
      "i: 117000 L: 327.220 norm:0.000122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 117500 L: 327.207 norm:0.000121\n",
      "i: 118000 L: 327.194 norm:0.000121\n",
      "i: 118500 L: 327.182 norm:0.000120\n",
      "i: 119000 L: 327.169 norm:0.000120\n",
      "i: 119500 L: 327.156 norm:0.000119\n",
      "i: 120000 L: 327.144 norm:0.000119\n",
      "i: 120500 L: 327.132 norm:0.000118\n",
      "i: 121000 L: 327.119 norm:0.000118\n",
      "i: 121500 L: 327.107 norm:0.000118\n",
      "i: 122000 L: 327.095 norm:0.000117\n",
      "i: 122500 L: 327.083 norm:0.000117\n",
      "i: 123000 L: 327.071 norm:0.000116\n",
      "i: 123500 L: 327.059 norm:0.000116\n",
      "i: 124000 L: 327.047 norm:0.000115\n",
      "i: 124500 L: 327.035 norm:0.000115\n",
      "i: 125000 L: 327.024 norm:0.000115\n",
      "i: 125500 L: 327.012 norm:0.000114\n",
      "i: 126000 L: 327.000 norm:0.000114\n",
      "i: 126500 L: 326.989 norm:0.000113\n",
      "i: 127000 L: 326.978 norm:0.000113\n",
      "i: 127500 L: 326.966 norm:0.000113\n",
      "i: 128000 L: 326.955 norm:0.000112\n",
      "i: 128500 L: 326.944 norm:0.000112\n",
      "i: 129000 L: 326.933 norm:0.000111\n",
      "i: 129500 L: 326.922 norm:0.000111\n",
      "i: 130000 L: 326.911 norm:0.000111\n",
      "i: 130500 L: 326.900 norm:0.000110\n",
      "i: 131000 L: 326.889 norm:0.000110\n",
      "i: 131500 L: 326.879 norm:0.000109\n",
      "i: 132000 L: 326.868 norm:0.000109\n",
      "i: 132500 L: 326.857 norm:0.000109\n",
      "i: 133000 L: 326.847 norm:0.000108\n",
      "i: 133500 L: 326.836 norm:0.000108\n",
      "i: 134000 L: 326.826 norm:0.000108\n",
      "i: 134500 L: 326.816 norm:0.000107\n",
      "i: 135000 L: 326.805 norm:0.000107\n",
      "i: 135500 L: 326.795 norm:0.000106\n",
      "i: 136000 L: 326.785 norm:0.000106\n",
      "i: 136500 L: 326.775 norm:0.000106\n",
      "i: 137000 L: 326.765 norm:0.000105\n",
      "i: 137500 L: 326.755 norm:0.000105\n",
      "i: 138000 L: 326.745 norm:0.000105\n",
      "i: 138500 L: 326.735 norm:0.000104\n",
      "i: 139000 L: 326.726 norm:0.000104\n",
      "i: 139500 L: 326.716 norm:0.000104\n",
      "i: 140000 L: 326.706 norm:0.000103\n",
      "i: 140500 L: 326.697 norm:0.000103\n",
      "i: 141000 L: 326.687 norm:0.000103\n",
      "i: 141500 L: 326.678 norm:0.000102\n",
      "i: 142000 L: 326.668 norm:0.000102\n",
      "i: 142500 L: 326.659 norm:0.000102\n",
      "i: 143000 L: 326.650 norm:0.000101\n",
      "i: 143500 L: 326.640 norm:0.000101\n",
      "i: 144000 L: 326.631 norm:0.000101\n",
      "i: 144500 L: 326.622 norm:0.000100\n",
      "i: 145000 L: 326.613 norm:0.000100\n",
      "i: 145500 L: 326.604 norm:0.000100\n",
      "i: 146000 L: 326.595 norm:0.000099\n",
      "i: 146500 L: 326.586 norm:0.000099\n",
      "i: 147000 L: 326.577 norm:0.000099\n",
      "i: 147500 L: 326.568 norm:0.000098\n",
      "i: 148000 L: 326.559 norm:0.000098\n",
      "i: 148500 L: 326.551 norm:0.000098\n",
      "i: 149000 L: 326.542 norm:0.000097\n",
      "i: 149500 L: 326.533 norm:0.000097\n",
      "i: 150000 L: 326.525 norm:0.000097\n",
      "i: 150500 L: 326.516 norm:0.000096\n",
      "i: 151000 L: 326.508 norm:0.000096\n",
      "i: 151500 L: 326.499 norm:0.000096\n",
      "i: 152000 L: 326.491 norm:0.000095\n",
      "i: 152500 L: 326.483 norm:0.000095\n",
      "i: 153000 L: 326.474 norm:0.000095\n",
      "i: 153500 L: 326.466 norm:0.000095\n",
      "i: 154000 L: 326.458 norm:0.000094\n",
      "i: 154500 L: 326.450 norm:0.000094\n",
      "i: 155000 L: 326.442 norm:0.000094\n",
      "i: 155500 L: 326.434 norm:0.000093\n",
      "i: 156000 L: 326.426 norm:0.000093\n",
      "i: 156500 L: 326.418 norm:0.000093\n",
      "i: 157000 L: 326.410 norm:0.000093\n",
      "i: 157500 L: 326.402 norm:0.000092\n",
      "i: 158000 L: 326.394 norm:0.000092\n",
      "i: 158500 L: 326.386 norm:0.000092\n",
      "i: 159000 L: 326.378 norm:0.000091\n",
      "i: 159500 L: 326.371 norm:0.000091\n",
      "i: 160000 L: 326.363 norm:0.000091\n",
      "i: 160500 L: 326.355 norm:0.000091\n",
      "i: 161000 L: 326.348 norm:0.000090\n",
      "i: 161500 L: 326.340 norm:0.000090\n",
      "i: 162000 L: 326.333 norm:0.000090\n",
      "i: 162500 L: 326.325 norm:0.000089\n",
      "i: 163000 L: 326.318 norm:0.000089\n",
      "i: 163500 L: 326.310 norm:0.000089\n",
      "i: 164000 L: 326.303 norm:0.000089\n",
      "i: 164500 L: 326.296 norm:0.000088\n",
      "i: 165000 L: 326.288 norm:0.000088\n",
      "i: 165500 L: 326.281 norm:0.000088\n",
      "i: 166000 L: 326.274 norm:0.000088\n",
      "i: 166500 L: 326.267 norm:0.000087\n",
      "i: 167000 L: 326.259 norm:0.000087\n",
      "i: 167500 L: 326.252 norm:0.000087\n",
      "i: 168000 L: 326.245 norm:0.000087\n",
      "i: 168500 L: 326.238 norm:0.000086\n",
      "i: 169000 L: 326.231 norm:0.000086\n",
      "i: 169500 L: 326.224 norm:0.000086\n",
      "i: 170000 L: 326.217 norm:0.000086\n",
      "i: 170500 L: 326.211 norm:0.000085\n",
      "i: 171000 L: 326.204 norm:0.000085\n",
      "i: 171500 L: 326.197 norm:0.000085\n",
      "i: 172000 L: 326.190 norm:0.000085\n",
      "i: 172500 L: 326.183 norm:0.000084\n",
      "i: 173000 L: 326.177 norm:0.000084\n",
      "i: 173500 L: 326.170 norm:0.000084\n",
      "i: 174000 L: 326.163 norm:0.000084\n",
      "i: 174500 L: 326.157 norm:0.000083\n",
      "i: 175000 L: 326.150 norm:0.000083\n",
      "i: 175500 L: 326.143 norm:0.000083\n",
      "i: 176000 L: 326.137 norm:0.000083\n",
      "i: 176500 L: 326.130 norm:0.000082\n",
      "i: 177000 L: 326.124 norm:0.000082\n",
      "i: 177500 L: 326.117 norm:0.000082\n",
      "i: 178000 L: 326.111 norm:0.000082\n",
      "i: 178500 L: 326.105 norm:0.000082\n",
      "i: 179000 L: 326.098 norm:0.000081\n",
      "i: 179500 L: 326.092 norm:0.000081\n",
      "i: 180000 L: 326.086 norm:0.000081\n",
      "i: 180500 L: 326.080 norm:0.000081\n",
      "i: 181000 L: 326.073 norm:0.000080\n",
      "i: 181500 L: 326.067 norm:0.000080\n",
      "i: 182000 L: 326.061 norm:0.000080\n",
      "i: 182500 L: 326.055 norm:0.000080\n",
      "i: 183000 L: 326.049 norm:0.000080\n",
      "i: 183500 L: 326.043 norm:0.000079\n",
      "i: 184000 L: 326.037 norm:0.000079\n",
      "i: 184500 L: 326.031 norm:0.000079\n",
      "i: 185000 L: 326.025 norm:0.000079\n",
      "i: 185500 L: 326.019 norm:0.000078\n",
      "i: 186000 L: 326.013 norm:0.000078\n",
      "i: 186500 L: 326.007 norm:0.000078\n",
      "i: 187000 L: 326.001 norm:0.000078\n",
      "i: 187500 L: 325.995 norm:0.000078\n",
      "i: 188000 L: 325.989 norm:0.000077\n",
      "i: 188500 L: 325.983 norm:0.000077\n",
      "i: 189000 L: 325.978 norm:0.000077\n",
      "i: 189500 L: 325.972 norm:0.000077\n",
      "i: 190000 L: 325.966 norm:0.000077\n",
      "i: 190500 L: 325.960 norm:0.000076\n",
      "i: 191000 L: 325.955 norm:0.000076\n",
      "i: 191500 L: 325.949 norm:0.000076\n",
      "i: 192000 L: 325.943 norm:0.000076\n",
      "i: 192500 L: 325.938 norm:0.000076\n",
      "i: 193000 L: 325.932 norm:0.000075\n",
      "i: 193500 L: 325.927 norm:0.000075\n",
      "i: 194000 L: 325.921 norm:0.000075\n",
      "i: 194500 L: 325.916 norm:0.000075\n",
      "i: 195000 L: 325.910 norm:0.000075\n",
      "i: 195500 L: 325.905 norm:0.000074\n",
      "i: 196000 L: 325.899 norm:0.000074\n",
      "i: 196500 L: 325.894 norm:0.000074\n",
      "i: 197000 L: 325.889 norm:0.000074\n",
      "i: 197500 L: 325.883 norm:0.000074\n",
      "i: 198000 L: 325.878 norm:0.000073\n",
      "i: 198500 L: 325.873 norm:0.000073\n",
      "i: 199000 L: 325.867 norm:0.000073\n",
      "i: 199500 L: 325.862 norm:0.000073\n",
      "W1 matrix: \n",
      "[[ -3.94569338  -1.75329736 -10.35482363]\n",
      " [ -4.04534416  -1.77069082 -10.64246258]]\n",
      "b1 vector: \n",
      "[[0.37335154]\n",
      " [0.71720262]\n",
      " [1.6551463 ]]\n",
      "W2 matrix: \n",
      "[[ 5.25920207]\n",
      " [ 4.25734337]\n",
      " [13.56365085]]\n",
      "b2 vector: \n",
      "[[0.76618306]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "n_iter = 200000                        # Number of iterations\n",
    "np.random.seed(0)\n",
    "W1 = np.random.randn(2,3)/((2*3)**2)   # Weight matrix 1.\n",
    "b1 = np.random.randn(3,1)/((3*1)**2)   # Bias vector 1.\n",
    "W2 = np.random.randn(3,1)/((3*1)**2)   # Weight matrix 2.\n",
    "b2 = np.random.randn(1,1)/((1*1)**2)   # Bias vector 2.\n",
    "\n",
    "# We will keep track of training loss over iterations.\n",
    "iterations = [0]\n",
    "L_list = [L(X_train, Y_train, W1, b1, W2, b2)]\n",
    "\n",
    "for i in range(n_iter):\n",
    "    \n",
    "    # gradient descent \n",
    "    \n",
    "    gradient_W1, gradient_b1, gradient_W2, gradient_b2 = \\\n",
    "        L_prime(X_train, Y_train, W1, b1, W2, b2)\n",
    "    \n",
    "    W1_new = W1 - learning_rate * gradient_W1\n",
    "    b1_new = b1 - learning_rate * gradient_b1\n",
    "    W2_new = W2 - learning_rate * gradient_W2\n",
    "    b2_new = b2 - learning_rate * gradient_b2\n",
    "    \n",
    "    iterations.append(i+1)\n",
    "    L_list.append(L(X_train, Y_train, W1_new, b1_new, W2_new, b2_new))\n",
    "    \n",
    "    # L1-norm of weight/bias changing.\n",
    "    norm = np.abs(W1_new-W1).sum() + np.abs(b1_new-b1).sum() + \\\n",
    "           np.abs(W2_new-W2).sum() + np.abs(b2_new-b2).sum() \n",
    "    \n",
    "    if i%500 == 0:\n",
    "        print('i: {:6d} L: {:.3f} norm:{:.6f}'.format(i, L_list[-1], norm))\n",
    "        \n",
    "    W1 = W1_new\n",
    "    b1 = b1_new\n",
    "    W2 = W2_new\n",
    "    b2 = b2_new\n",
    "    \n",
    "print ('W1 matrix: \\n' + str(W1))\n",
    "print ('b1 vector: \\n' + str(b1))\n",
    "print ('W2 matrix: \\n' + str(W2))\n",
    "print ('b2 vector: \\n' + str(b2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation In Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how simple this is using keras :)\n",
    "# Try adding more layers, changing activation to e.g. 'tanh' or 'relu' or 'sigmoid' and compare results!\n",
    "# You may notice that \"linear\" works best and thats obvious because our data is fairly linear\n",
    "# You can also try changing the data generated\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(2, activation='linear'),\n",
    "    # typically, more neurons, the more capable the network, but be wary of overfitting\n",
    "    tf.keras.layers.Dense(32, activation='linear'), \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# we specify we want to use something known as the Adam optimizer to optimize the loss and minimize it\n",
    "# Adam, like SGD, tries to minimize the loss function. In a future workshop we will explain why Adam runs much \n",
    "# faster and has higher accuracy\n",
    "# the loss we use here is known as Mean Squared Error\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "32/32 [==============================] - 0s 644us/step - loss: 0.0291 - mse: 0.0291\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 643us/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 640us/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 669us/step - loss: 7.6675e-04 - mse: 7.6675e-04\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 720us/step - loss: 4.2612e-04 - mse: 4.2612e-04\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 2.4964e-04 - mse: 2.4964e-04\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 1.7099e-04 - mse: 1.7099e-04\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 1.3646e-04 - mse: 1.3646e-04\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 681us/step - loss: 1.2460e-04 - mse: 1.2460e-04\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 813us/step - loss: 1.2150e-04 - mse: 1.2150e-04\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 724us/step - loss: 1.1809e-04 - mse: 1.1809e-04\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 731us/step - loss: 1.1740e-04 - mse: 1.1740e-04\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 878us/step - loss: 1.1678e-04 - mse: 1.1678e-04\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 742us/step - loss: 1.1610e-04 - mse: 1.1610e-04\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 750us/step - loss: 1.1597e-04 - mse: 1.1597e-04\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 713us/step - loss: 1.1616e-04 - mse: 1.1616e-04\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 640us/step - loss: 1.1607e-04 - mse: 1.1607e-04\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 723us/step - loss: 1.1423e-04 - mse: 1.1423e-04\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 1.1284e-04 - mse: 1.1284e-04\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 756us/step - loss: 1.1257e-04 - mse: 1.1257e-04\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 619us/step - loss: 1.1185e-04 - mse: 1.1185e-04\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 737us/step - loss: 1.1102e-04 - mse: 1.1102e-04\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 1.1007e-04 - mse: 1.1007e-04\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 739us/step - loss: 1.0884e-04 - mse: 1.0884e-04\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 715us/step - loss: 1.0848e-04 - mse: 1.0848e-04\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 691us/step - loss: 1.0747e-04 - mse: 1.0747e-04\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 678us/step - loss: 1.0664e-04 - mse: 1.0664e-04\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 668us/step - loss: 1.0568e-04 - mse: 1.0568e-04\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 625us/step - loss: 1.0628e-04 - mse: 1.0628e-04\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 652us/step - loss: 1.0397e-04 - mse: 1.0397e-04\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 1.0350e-04 - mse: 1.0350e-04\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 719us/step - loss: 1.0312e-04 - mse: 1.0312e-04\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 756us/step - loss: 1.0124e-04 - mse: 1.0124e-04\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 622us/step - loss: 1.0106e-04 - mse: 1.0106e-04\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 650us/step - loss: 9.9520e-05 - mse: 9.9520e-05\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 9.8201e-05 - mse: 9.8201e-05\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 609us/step - loss: 9.7455e-05 - mse: 9.7455e-05\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 611us/step - loss: 9.6421e-05 - mse: 9.6421e-05\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 610us/step - loss: 9.6483e-05 - mse: 9.6483e-05\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 626us/step - loss: 9.5289e-05 - mse: 9.5289e-05\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 9.4663e-05 - mse: 9.4663e-05\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 609us/step - loss: 9.3896e-05 - mse: 9.3896e-05\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 738us/step - loss: 9.4092e-05 - mse: 9.4092e-05\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 639us/step - loss: 9.1201e-05 - mse: 9.1201e-05\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 565us/step - loss: 8.9839e-05 - mse: 8.9839e-05\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 644us/step - loss: 8.8285e-05 - mse: 8.8285e-05\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 625us/step - loss: 8.7566e-05 - mse: 8.7566e-05\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 8.6256e-05 - mse: 8.6256e-05\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 617us/step - loss: 8.5227e-05 - mse: 8.5227e-05\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 659us/step - loss: 8.4204e-05 - mse: 8.4204e-05\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 632us/step - loss: 8.3142e-05 - mse: 8.3142e-05\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 8.2410e-05 - mse: 8.2410e-05\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 695us/step - loss: 8.2492e-05 - mse: 8.2492e-05\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 634us/step - loss: 8.0422e-05 - mse: 8.0422e-05\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 617us/step - loss: 7.8784e-05 - mse: 7.8784e-05\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 610us/step - loss: 7.7882e-05 - mse: 7.7882e-05\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 7.6614e-05 - mse: 7.6614e-05\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 611us/step - loss: 7.6164e-05 - mse: 7.6164e-05\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 7.4433e-05 - mse: 7.4433e-05\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 575us/step - loss: 7.3814e-05 - mse: 7.3814e-05\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 565us/step - loss: 7.1854e-05 - mse: 7.1854e-05\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 599us/step - loss: 7.2217e-05 - mse: 7.2217e-05\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 574us/step - loss: 7.0962e-05 - mse: 7.0962e-05\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 656us/step - loss: 7.0471e-05 - mse: 7.0471e-05\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 581us/step - loss: 6.9786e-05 - mse: 6.9786e-05\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 556us/step - loss: 6.7550e-05 - mse: 6.7550e-05\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 562us/step - loss: 6.5709e-05 - mse: 6.5709e-05\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 587us/step - loss: 6.5343e-05 - mse: 6.5343e-05\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 569us/step - loss: 6.4447e-05 - mse: 6.4447e-05\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 564us/step - loss: 6.2399e-05 - mse: 6.2399e-05\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 6.2069e-05 - mse: 6.2069e-05\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 6.0481e-05 - mse: 6.0481e-05\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 5.8938e-05 - mse: 5.8938e-05\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 558us/step - loss: 5.8705e-05 - mse: 5.8705e-05\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 571us/step - loss: 5.7782e-05 - mse: 5.7782e-05\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 651us/step - loss: 5.5690e-05 - mse: 5.5690e-05\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 593us/step - loss: 5.4683e-05 - mse: 5.4683e-05\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 5.3363e-05 - mse: 5.3363e-05\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 5.3707e-05 - mse: 5.3707e-05\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 5.3519e-05 - mse: 5.3519e-05\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 546us/step - loss: 5.0265e-05 - mse: 5.0265e-05\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 587us/step - loss: 4.9349e-05 - mse: 4.9349e-05\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 548us/step - loss: 4.8285e-05 - mse: 4.8285e-05\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 547us/step - loss: 4.7107e-05 - mse: 4.7107e-05\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 525us/step - loss: 4.7153e-05 - mse: 4.7153e-05\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 546us/step - loss: 4.5140e-05 - mse: 4.5140e-05\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 4.4730e-05 - mse: 4.4730e-05\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 588us/step - loss: 4.3240e-05 - mse: 4.3240e-05\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 4.3202e-05 - mse: 4.3202e-05\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 551us/step - loss: 4.1930e-05 - mse: 4.1930e-05\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 546us/step - loss: 4.0008e-05 - mse: 4.0008e-05\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 545us/step - loss: 3.9081e-05 - mse: 3.9081e-05\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 552us/step - loss: 3.8460e-05 - mse: 3.8460e-05\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 550us/step - loss: 3.7053e-05 - mse: 3.7053e-05\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 3.6599e-05 - mse: 3.6599e-05\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 3.5804e-05 - mse: 3.5804e-05\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 633us/step - loss: 3.5706e-05 - mse: 3.5706e-05\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 545us/step - loss: 3.4799e-05 - mse: 3.4799e-05\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 666us/step - loss: 3.2034e-05 - mse: 3.2034e-05\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 612us/step - loss: 3.1028e-05 - mse: 3.1028e-05\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 570us/step - loss: 3.1266e-05 - mse: 3.1266e-05\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 566us/step - loss: 2.9556e-05 - mse: 2.9556e-05\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 565us/step - loss: 2.8907e-05 - mse: 2.8907e-05\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 562us/step - loss: 2.7357e-05 - mse: 2.7357e-05\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 551us/step - loss: 2.6554e-05 - mse: 2.6554e-05\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 2.6265e-05 - mse: 2.6265e-05\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 569us/step - loss: 2.5831e-05 - mse: 2.5831e-05\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 614us/step - loss: 2.5515e-05 - mse: 2.5515e-05\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 2.3313e-05 - mse: 2.3313e-05\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 2.2987e-05 - mse: 2.2987e-05\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 2.1296e-05 - mse: 2.1296e-05\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 593us/step - loss: 2.0567e-05 - mse: 2.0567e-05\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 572us/step - loss: 1.9890e-05 - mse: 1.9890e-05\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 570us/step - loss: 1.8969e-05 - mse: 1.8969e-05\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 1.8577e-05 - mse: 1.8577e-05\n",
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 1.7585e-05 - mse: 1.7585e-05\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 1.7164e-05 - mse: 1.7164e-05\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 1.6615e-05 - mse: 1.6615e-05\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 565us/step - loss: 1.5322e-05 - mse: 1.5322e-05\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 679us/step - loss: 1.5083e-05 - mse: 1.5083e-05\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 634us/step - loss: 1.4713e-05 - mse: 1.4713e-05\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 674us/step - loss: 1.3734e-05 - mse: 1.3734e-05\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 1.2991e-05 - mse: 1.2991e-05\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 1.2287e-05 - mse: 1.2287e-05\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 605us/step - loss: 1.2146e-05 - mse: 1.2146e-05\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 1.1064e-05 - mse: 1.1064e-05\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 609us/step - loss: 1.1234e-05 - mse: 1.1234e-05\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 1.0801e-05 - mse: 1.0801e-05\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 659us/step - loss: 1.0017e-05 - mse: 1.0017e-05\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 671us/step - loss: 9.4955e-06 - mse: 9.4955e-06\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 657us/step - loss: 8.5216e-06 - mse: 8.5216e-06\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 8.4011e-06 - mse: 8.4011e-06\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 669us/step - loss: 7.4838e-06 - mse: 7.4838e-06\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 665us/step - loss: 7.2467e-06 - mse: 7.2467e-06\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 585us/step - loss: 6.9766e-06 - mse: 6.9766e-06\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 701us/step - loss: 6.6716e-06 - mse: 6.6716e-06\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 697us/step - loss: 6.1938e-06 - mse: 6.1938e-06\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 748us/step - loss: 5.6916e-06 - mse: 5.6916e-06\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 610us/step - loss: 5.1508e-06 - mse: 5.1508e-06\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 755us/step - loss: 4.9004e-06 - mse: 4.9004e-06\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 616us/step - loss: 4.4652e-06 - mse: 4.4652e-06\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 676us/step - loss: 4.4894e-06 - mse: 4.4894e-06\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 4.8835e-06 - mse: 4.8835e-06\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 569us/step - loss: 3.9280e-06 - mse: 3.9280e-06\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 630us/step - loss: 3.4348e-06 - mse: 3.4348e-06\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 725us/step - loss: 3.1370e-06 - mse: 3.1370e-06\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 813us/step - loss: 2.7647e-06 - mse: 2.7647e-06\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 650us/step - loss: 2.5169e-06 - mse: 2.5169e-06\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 686us/step - loss: 2.5089e-06 - mse: 2.5089e-06\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 765us/step - loss: 2.2199e-06 - mse: 2.2199e-06\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 640us/step - loss: 2.0586e-06 - mse: 2.0586e-06\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 659us/step - loss: 1.8555e-06 - mse: 1.8555e-06\n",
      "Epoch 154/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 723us/step - loss: 1.6406e-06 - mse: 1.6406e-06\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 688us/step - loss: 1.5539e-06 - mse: 1.5539e-06\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 1.5151e-06 - mse: 1.5151e-06\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 575us/step - loss: 1.2022e-06 - mse: 1.2022e-06\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 559us/step - loss: 1.1492e-06 - mse: 1.1492e-06\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 625us/step - loss: 1.0038e-06 - mse: 1.0038e-06\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 572us/step - loss: 9.1063e-07 - mse: 9.1063e-07\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 560us/step - loss: 8.0316e-07 - mse: 8.0316e-07\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 7.4932e-07 - mse: 7.4932e-07\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 619us/step - loss: 7.1941e-07 - mse: 7.1941e-07\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 6.8430e-07 - mse: 6.8430e-07\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 574us/step - loss: 5.2486e-07 - mse: 5.2486e-07\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 5.2137e-07 - mse: 5.2137e-07\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 570us/step - loss: 4.0742e-07 - mse: 4.0742e-07\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 3.9466e-07 - mse: 3.9466e-07\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 571us/step - loss: 3.6894e-07 - mse: 3.6894e-07\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 3.2496e-07 - mse: 3.2496e-07\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 704us/step - loss: 2.5432e-07 - mse: 2.5432e-07\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 610us/step - loss: 2.3129e-07 - mse: 2.3129e-07\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 2.2668e-07 - mse: 2.2668e-07\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 640us/step - loss: 1.6509e-07 - mse: 1.6509e-07\n",
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 597us/step - loss: 1.6493e-07 - mse: 1.6493e-07\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 1.7041e-07 - mse: 1.7041e-07\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 605us/step - loss: 1.6401e-07 - mse: 1.6401e-07\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 1.0260e-07 - mse: 1.0260e-07\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 8.3592e-08 - mse: 8.3592e-08\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 596us/step - loss: 8.1423e-08 - mse: 8.1423e-08\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 700us/step - loss: 5.7478e-08 - mse: 5.7478e-08\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 638us/step - loss: 7.0326e-08 - mse: 7.0326e-08\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 593us/step - loss: 4.4548e-08 - mse: 4.4548e-08\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 547us/step - loss: 4.2306e-08 - mse: 4.2306e-08\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 575us/step - loss: 4.4257e-08 - mse: 4.4257e-08\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 2.4465e-08 - mse: 2.4465e-08\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 2.0719e-08 - mse: 2.0719e-08\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 564us/step - loss: 1.9000e-08 - mse: 1.9000e-08\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 561us/step - loss: 1.5200e-08 - mse: 1.5200e-08\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 570us/step - loss: 1.2607e-08 - mse: 1.2607e-08\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 606us/step - loss: 9.7686e-09 - mse: 9.7686e-09\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 633us/step - loss: 8.4654e-09 - mse: 8.4654e-09\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 678us/step - loss: 6.8450e-09 - mse: 6.8450e-09\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 6.0019e-09 - mse: 6.0019e-09\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 571us/step - loss: 5.6224e-09 - mse: 5.6224e-09\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 575us/step - loss: 5.2990e-09 - mse: 5.2990e-09\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 553us/step - loss: 3.5173e-09 - mse: 3.5173e-09\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 545us/step - loss: 2.6874e-09 - mse: 2.6874e-09\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 533us/step - loss: 1.9156e-09 - mse: 1.9156e-09\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 570us/step - loss: 1.9034e-09 - mse: 1.9034e-09\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 541us/step - loss: 1.3903e-09 - mse: 1.3903e-09\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 543us/step - loss: 1.1635e-09 - mse: 1.1635e-09\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 529us/step - loss: 1.0871e-09 - mse: 1.0871e-09\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 568us/step - loss: 7.8711e-10 - mse: 7.8711e-10\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 578us/step - loss: 6.6849e-10 - mse: 6.6849e-10\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 568us/step - loss: 4.1411e-10 - mse: 4.1411e-10\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 555us/step - loss: 6.1037e-10 - mse: 6.1037e-10\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 560us/step - loss: 5.1197e-10 - mse: 5.1197e-10\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 550us/step - loss: 4.7814e-10 - mse: 4.7814e-10\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 567us/step - loss: 3.0463e-10 - mse: 3.0463e-10\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 558us/step - loss: 1.2504e-10 - mse: 1.2504e-10\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 539us/step - loss: 8.6021e-11 - mse: 8.6021e-11\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 1.2922e-10 - mse: 1.2922e-10\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 616us/step - loss: 5.5269e-11 - mse: 5.5269e-11\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 617us/step - loss: 5.1724e-11 - mse: 5.1724e-11\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 611us/step - loss: 3.0520e-11 - mse: 3.0520e-11\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 3.8122e-11 - mse: 3.8122e-11\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 568us/step - loss: 1.6166e-11 - mse: 1.6166e-11\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 575us/step - loss: 1.2855e-11 - mse: 1.2855e-11\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 581us/step - loss: 1.2205e-11 - mse: 1.2205e-11\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 1.1834e-11 - mse: 1.1834e-11\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 728us/step - loss: 5.1555e-12 - mse: 5.1555e-12\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 671us/step - loss: 3.9754e-12 - mse: 3.9754e-12\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 856us/step - loss: 3.4170e-12 - mse: 3.4170e-12\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 612us/step - loss: 3.6185e-12 - mse: 3.6185e-12\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 1.2784e-12 - mse: 1.2784e-12\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 586us/step - loss: 3.0369e-12 - mse: 3.0369e-12\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 586us/step - loss: 1.1925e-12 - mse: 1.1925e-12\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 680us/step - loss: 4.1172e-13 - mse: 4.1172e-13\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 573us/step - loss: 4.4845e-13 - mse: 4.4845e-13\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 2.6782e-13 - mse: 2.6782e-13\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 1.5392e-13 - mse: 1.5392e-13\n",
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 597us/step - loss: 1.7117e-13 - mse: 1.7117e-13\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 1.8830e-13 - mse: 1.8830e-13\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 680us/step - loss: 9.2652e-14 - mse: 9.2652e-14\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 1.3453e-13 - mse: 1.3453e-13\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 606us/step - loss: 1.6667e-13 - mse: 1.6667e-13\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 616us/step - loss: 1.2626e-13 - mse: 1.2626e-13\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 651us/step - loss: 2.3831e-14 - mse: 2.3831e-14\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 596us/step - loss: 1.2154e-14 - mse: 1.2154e-14\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 618us/step - loss: 1.0682e-14 - mse: 1.0682e-14\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 1.4448e-14 - mse: 1.4448e-14\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 1.5627e-14 - mse: 1.5627e-14\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 617us/step - loss: 7.7461e-15 - mse: 7.7461e-15\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 670us/step - loss: 9.9306e-15 - mse: 9.9306e-15\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 664us/step - loss: 8.8231e-15 - mse: 8.8231e-15\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 599us/step - loss: 8.1759e-15 - mse: 8.1759e-15\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 615us/step - loss: 6.8383e-15 - mse: 6.8383e-15\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 588us/step - loss: 1.4881e-14 - mse: 1.4881e-14\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 567us/step - loss: 5.5253e-15 - mse: 5.5253e-15\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 559us/step - loss: 7.0731e-15 - mse: 7.0731e-15\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 596us/step - loss: 4.0110e-14 - mse: 4.0110e-14\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 7.0827e-14 - mse: 7.0827e-14\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 578us/step - loss: 2.9287e-14 - mse: 2.9287e-14\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 1.2552e-14 - mse: 1.2552e-14\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 597us/step - loss: 6.6150e-15 - mse: 6.6150e-15\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 688us/step - loss: 4.9010e-15 - mse: 4.9010e-15\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 605us/step - loss: 1.0782e-14 - mse: 1.0782e-14\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 584us/step - loss: 2.4542e-14 - mse: 2.4542e-14\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 577us/step - loss: 8.6705e-14 - mse: 8.6705e-14\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 1.5353e-14 - mse: 1.5353e-14\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 586us/step - loss: 3.9706e-15 - mse: 3.9706e-15\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 626us/step - loss: 1.4623e-14 - mse: 1.4623e-14\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 610us/step - loss: 7.3538e-14 - mse: 7.3538e-14\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 4.6436e-15 - mse: 4.6436e-15\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 641us/step - loss: 1.6940e-14 - mse: 1.6940e-14\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 3.2811e-15 - mse: 3.2811e-15\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 704us/step - loss: 2.9299e-15 - mse: 2.9299e-15\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 1.5234e-14 - mse: 1.5234e-14\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 606us/step - loss: 4.4164e-14 - mse: 4.4164e-14\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 2.6491e-13 - mse: 2.6491e-13\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 572us/step - loss: 2.6168e-12 - mse: 2.6168e-12\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 7.3586e-13 - mse: 7.3586e-13\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 629us/step - loss: 1.6353e-13 - mse: 1.6353e-13\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 2.0724e-13 - mse: 2.0724e-13\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 593us/step - loss: 2.0919e-12 - mse: 2.0919e-12\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 589us/step - loss: 5.7326e-12 - mse: 5.7326e-12\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 660us/step - loss: 2.5380e-11 - mse: 2.5380e-11\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 648us/step - loss: 1.6938e-08 - mse: 1.6938e-08\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 2.8733e-07 - mse: 2.8733e-07\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 597us/step - loss: 2.2043e-07 - mse: 2.2043e-07\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 2.5034e-06 - mse: 2.5034e-06\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 625us/step - loss: 1.0574e-07 - mse: 1.0574e-07\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 610us/step - loss: 3.1093e-09 - mse: 3.1093e-09\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 588us/step - loss: 1.9679e-10 - mse: 1.9679e-10\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 3.1975e-11 - mse: 3.1975e-11\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 635us/step - loss: 1.2942e-11 - mse: 1.2942e-11\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 660us/step - loss: 2.4486e-12 - mse: 2.4486e-12\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 1.1762e-12 - mse: 1.1762e-12\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 555us/step - loss: 6.9977e-13 - mse: 6.9977e-13\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 6.1794e-13 - mse: 6.1794e-13\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 4.5468e-13 - mse: 4.5468e-13\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 7.4090e-13 - mse: 7.4090e-13\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 1.6996e-13 - mse: 1.6996e-13\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 3.6167e-14 - mse: 3.6167e-14\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 588us/step - loss: 1.6589e-13 - mse: 1.6589e-13\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 549us/step - loss: 1.5451e-12 - mse: 1.5451e-12\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 0s 659us/step - loss: 7.9110e-13 - mse: 7.9110e-13\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 0s 670us/step - loss: 5.0989e-13 - mse: 5.0989e-13\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 1.5704e-13 - mse: 1.5704e-13\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 0s 622us/step - loss: 4.2466e-13 - mse: 4.2466e-13\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 0s 638us/step - loss: 1.8823e-11 - mse: 1.8823e-11\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 0s 572us/step - loss: 5.9981e-11 - mse: 5.9981e-11\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 0s 570us/step - loss: 2.0810e-11 - mse: 2.0810e-11\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 8.0543e-11 - mse: 8.0543e-11\n",
      "Epoch 306/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 616us/step - loss: 1.4361e-11 - mse: 1.4361e-11\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 0s 606us/step - loss: 2.4086e-12 - mse: 2.4086e-12\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 7.0834e-08 - mse: 7.0834e-08\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 0s 615us/step - loss: 1.7184e-06 - mse: 1.7184e-06\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 0s 680us/step - loss: 3.6476e-06 - mse: 3.6476e-06\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 3.1631e-07 - mse: 3.1631e-07\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 0s 573us/step - loss: 1.1704e-08 - mse: 1.1704e-08\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 0s 599us/step - loss: 3.1374e-09 - mse: 3.1374e-09\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 0s 574us/step - loss: 9.5556e-10 - mse: 9.5556e-10\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 0s 616us/step - loss: 7.0577e-10 - mse: 7.0577e-10\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 0s 611us/step - loss: 3.6800e-10 - mse: 3.6800e-10\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 0s 588us/step - loss: 2.2431e-10 - mse: 2.2431e-10\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 4.3912e-10 - mse: 4.3912e-10\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 0s 539us/step - loss: 8.9740e-11 - mse: 8.9740e-11\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 0s 661us/step - loss: 8.5203e-11 - mse: 8.5203e-11\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 3.5625e-11 - mse: 3.5625e-11\n",
      "Epoch 322/1000\n",
      "32/32 [==============================] - 0s 568us/step - loss: 1.2804e-11 - mse: 1.2804e-11\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 0s 584us/step - loss: 2.3068e-11 - mse: 2.3068e-11\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 1.9325e-12 - mse: 1.9325e-12\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 0s 588us/step - loss: 8.6381e-13 - mse: 8.6381e-13\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 0s 593us/step - loss: 4.8213e-13 - mse: 4.8213e-13\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 0s 600us/step - loss: 2.3806e-12 - mse: 2.3806e-12\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 1.9085e-12 - mse: 1.9085e-12\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 6.5751e-13 - mse: 6.5751e-13\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 1.5045e-13 - mse: 1.5045e-13\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 0s 656us/step - loss: 1.3223e-13 - mse: 1.3223e-13\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 0s 633us/step - loss: 9.5493e-14 - mse: 9.5493e-14\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 8.2408e-14 - mse: 8.2408e-14\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 0s 642us/step - loss: 1.0764e-14 - mse: 1.0764e-14\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 0s 555us/step - loss: 2.4159e-13 - mse: 2.4159e-13\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 0s 615us/step - loss: 1.4849e-13 - mse: 1.4849e-13\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 9.2871e-13 - mse: 9.2871e-13\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 0s 549us/step - loss: 4.1448e-12 - mse: 4.1448e-12\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 0s 599us/step - loss: 4.1384e-12 - mse: 4.1384e-12\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 2.2745e-13 - mse: 2.2745e-13\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 2.1202e-13 - mse: 2.1202e-13\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 0s 705us/step - loss: 5.6930e-12 - mse: 5.6930e-12\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 9.4888e-12 - mse: 9.4888e-12\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 0s 577us/step - loss: 1.2013e-10 - mse: 1.2013e-10\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 0s 605us/step - loss: 6.8797e-09 - mse: 6.8797e-09\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 0s 679us/step - loss: 3.2188e-06 - mse: 3.2188e-06\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 0s 589us/step - loss: 1.1908e-07 - mse: 1.1908e-07\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 0s 636us/step - loss: 3.4112e-09 - mse: 3.4112e-09\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 1.0576e-09 - mse: 1.0576e-09\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 7.1062e-10 - mse: 7.1062e-10\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 0s 642us/step - loss: 6.9818e-10 - mse: 6.9818e-10\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 0s 637us/step - loss: 1.2245e-10 - mse: 1.2245e-10\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 0s 647us/step - loss: 1.1656e-10 - mse: 1.1656e-10\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 0s 677us/step - loss: 3.2152e-11 - mse: 3.2152e-11\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 0s 649us/step - loss: 8.0581e-11 - mse: 8.0581e-11\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 3.7920e-11 - mse: 3.7920e-11\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 0s 651us/step - loss: 3.7077e-12 - mse: 3.7077e-12\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 0s 572us/step - loss: 1.6775e-12 - mse: 1.6775e-12\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 7.9930e-13 - mse: 7.9930e-13\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 0s 587us/step - loss: 6.3347e-13 - mse: 6.3347e-13\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 0s 651us/step - loss: 9.9936e-13 - mse: 9.9936e-13\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 0s 683us/step - loss: 1.4216e-12 - mse: 1.4216e-12\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 0s 674us/step - loss: 5.3545e-13 - mse: 5.3545e-13\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 0s 645us/step - loss: 7.1450e-13 - mse: 7.1450e-13\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 0s 580us/step - loss: 4.4672e-13 - mse: 4.4672e-13\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 1.6506e-12 - mse: 1.6506e-12\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 1.5536e-11 - mse: 1.5536e-11\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 5.9741e-11 - mse: 5.9741e-11\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 0s 580us/step - loss: 1.5922e-09 - mse: 1.5922e-09\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 0s 548us/step - loss: 4.0875e-08 - mse: 4.0875e-08\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 0s 574us/step - loss: 1.8541e-07 - mse: 1.8541e-07\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 0s 563us/step - loss: 1.1295e-06 - mse: 1.1295e-06\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 0s 695us/step - loss: 3.1787e-07 - mse: 3.1787e-07\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 0s 568us/step - loss: 1.3324e-08 - mse: 1.3324e-08\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 6.0161e-10 - mse: 6.0161e-10\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 0s 605us/step - loss: 4.9129e-11 - mse: 4.9129e-11\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 0s 612us/step - loss: 3.5153e-11 - mse: 3.5153e-11\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 5.0928e-11 - mse: 5.0928e-11\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 3.5571e-11 - mse: 3.5571e-11\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 0s 573us/step - loss: 3.6672e-11 - mse: 3.6672e-11\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 0s 589us/step - loss: 2.0321e-10 - mse: 2.0321e-10\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 830us/step - loss: 2.5089e-09 - mse: 2.5089e-09\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 0s 661us/step - loss: 1.1844e-09 - mse: 1.1844e-09\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 0s 615us/step - loss: 1.0320e-07 - mse: 1.0320e-07\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 0s 648us/step - loss: 6.9328e-08 - mse: 6.9328e-08\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 9.3098e-08 - mse: 9.3098e-08\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 5.3867e-08 - mse: 5.3867e-08\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 1.1675e-07 - mse: 1.1675e-07\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 0s 609us/step - loss: 2.1439e-06 - mse: 2.1439e-06\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 2.0782e-06 - mse: 2.0782e-06\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 0s 596us/step - loss: 3.2022e-07 - mse: 3.2022e-07\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 0s 618us/step - loss: 1.4396e-08 - mse: 1.4396e-08\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 0s 610us/step - loss: 4.0649e-09 - mse: 4.0649e-09\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 2.0709e-09 - mse: 2.0709e-09\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 7.5263e-10 - mse: 7.5263e-10\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 0s 646us/step - loss: 3.1039e-10 - mse: 3.1039e-10\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 1.8673e-10 - mse: 1.8673e-10\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 0s 593us/step - loss: 4.4556e-11 - mse: 4.4556e-11\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 1.4822e-11 - mse: 1.4822e-11\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 9.9391e-12 - mse: 9.9391e-12\n",
      "Epoch 401/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 2.2649e-11 - mse: 2.2649e-11\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 0s 600us/step - loss: 5.5970e-12 - mse: 5.5970e-12\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 0s 584us/step - loss: 3.0351e-12 - mse: 3.0351e-12\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 0s 642us/step - loss: 2.5150e-12 - mse: 2.5150e-12\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 0s 648us/step - loss: 2.0365e-13 - mse: 2.0365e-13\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 5.8980e-14 - mse: 5.8980e-14\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 0s 626us/step - loss: 7.8192e-14 - mse: 7.8192e-14\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 1.0709e-13 - mse: 1.0709e-13\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 0s 722us/step - loss: 8.0377e-14 - mse: 8.0377e-14\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 0s 635us/step - loss: 6.6827e-15 - mse: 6.6827e-15\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 0s 561us/step - loss: 4.3701e-15 - mse: 4.3701e-15\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 4.8810e-15 - mse: 4.8810e-15\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 1.7862e-13 - mse: 1.7862e-13\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 6.2402e-13 - mse: 6.2402e-13\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 0s 650us/step - loss: 1.5629e-13 - mse: 1.5629e-13\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 0s 588us/step - loss: 8.1761e-15 - mse: 8.1761e-15\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 0s 587us/step - loss: 3.2605e-13 - mse: 3.2605e-13\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 0s 626us/step - loss: 1.8320e-13 - mse: 1.8320e-13\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 0s 609us/step - loss: 3.9776e-13 - mse: 3.9776e-13\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 9.7870e-13 - mse: 9.7870e-13\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 1.4790e-11 - mse: 1.4790e-11\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 2.3244e-08 - mse: 2.3244e-08\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 0s 597us/step - loss: 5.8931e-07 - mse: 5.8931e-07\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 0s 612us/step - loss: 1.1852e-06 - mse: 1.1852e-06\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 0s 734us/step - loss: 1.5753e-07 - mse: 1.5753e-07\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 0s 657us/step - loss: 3.0097e-09 - mse: 3.0097e-09\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 0s 643us/step - loss: 3.6370e-10 - mse: 3.6370e-10\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 0s 584us/step - loss: 5.7905e-11 - mse: 5.7905e-11\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 0s 631us/step - loss: 2.9649e-10 - mse: 2.9649e-10\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 0s 600us/step - loss: 1.3695e-10 - mse: 1.3695e-10\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 1.1821e-11 - mse: 1.1821e-11\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 1.6680e-12 - mse: 1.6680e-12\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 0s 587us/step - loss: 3.6948e-13 - mse: 3.6948e-13\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 1.8958e-13 - mse: 1.8958e-13\n",
      "Epoch 435/1000\n",
      "32/32 [==============================] - 0s 726us/step - loss: 1.7539e-14 - mse: 1.7539e-14\n",
      "Epoch 436/1000\n",
      "32/32 [==============================] - 0s 616us/step - loss: 6.7897e-15 - mse: 6.7897e-15\n",
      "Epoch 437/1000\n",
      "32/32 [==============================] - 0s 585us/step - loss: 9.8036e-14 - mse: 9.8036e-14\n",
      "Epoch 438/1000\n",
      "32/32 [==============================] - 0s 585us/step - loss: 1.0159e-14 - mse: 1.0159e-14\n",
      "Epoch 439/1000\n",
      "32/32 [==============================] - 0s 666us/step - loss: 4.0793e-13 - mse: 4.0793e-13\n",
      "Epoch 440/1000\n",
      "32/32 [==============================] - 0s 648us/step - loss: 6.6319e-11 - mse: 6.6319e-11\n",
      "Epoch 441/1000\n",
      "32/32 [==============================] - 0s 584us/step - loss: 1.6030e-08 - mse: 1.6030e-08\n",
      "Epoch 442/1000\n",
      "32/32 [==============================] - 0s 566us/step - loss: 2.4098e-09 - mse: 2.4098e-09\n",
      "Epoch 443/1000\n",
      "32/32 [==============================] - 0s 558us/step - loss: 2.2523e-10 - mse: 2.2523e-10\n",
      "Epoch 444/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 2.1362e-06 - mse: 2.1362e-06\n",
      "Epoch 445/1000\n",
      "32/32 [==============================] - 0s 654us/step - loss: 2.3222e-06 - mse: 2.3222e-06\n",
      "Epoch 446/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 9.7666e-08 - mse: 9.7666e-08\n",
      "Epoch 447/1000\n",
      "32/32 [==============================] - 0s 637us/step - loss: 1.7674e-08 - mse: 1.7674e-08\n",
      "Epoch 448/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 2.0081e-09 - mse: 2.0081e-09\n",
      "Epoch 449/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 7.2230e-10 - mse: 7.2230e-10\n",
      "Epoch 450/1000\n",
      "32/32 [==============================] - 0s 558us/step - loss: 1.3883e-10 - mse: 1.3883e-10\n",
      "Epoch 451/1000\n",
      "32/32 [==============================] - 0s 596us/step - loss: 6.1507e-11 - mse: 6.1507e-11\n",
      "Epoch 452/1000\n",
      "32/32 [==============================] - 0s 569us/step - loss: 2.7551e-11 - mse: 2.7551e-11\n",
      "Epoch 453/1000\n",
      "32/32 [==============================] - 0s 551us/step - loss: 1.6752e-11 - mse: 1.6752e-11\n",
      "Epoch 454/1000\n",
      "32/32 [==============================] - 0s 575us/step - loss: 5.3208e-12 - mse: 5.3208e-12\n",
      "Epoch 455/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 5.7626e-12 - mse: 5.7626e-12\n",
      "Epoch 456/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 1.0625e-12 - mse: 1.0625e-12\n",
      "Epoch 457/1000\n",
      "32/32 [==============================] - 0s 645us/step - loss: 1.6712e-12 - mse: 1.6712e-12\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 631us/step - loss: 8.8055e-13 - mse: 8.8055e-13\n",
      "Epoch 459/1000\n",
      "32/32 [==============================] - 0s 649us/step - loss: 1.8067e-12 - mse: 1.8067e-12\n",
      "Epoch 460/1000\n",
      "32/32 [==============================] - 0s 650us/step - loss: 3.6642e-13 - mse: 3.6642e-13\n",
      "Epoch 461/1000\n",
      "32/32 [==============================] - 0s 600us/step - loss: 1.9876e-14 - mse: 1.9876e-14\n",
      "Epoch 462/1000\n",
      "32/32 [==============================] - 0s 594us/step - loss: 1.4925e-13 - mse: 1.4925e-13\n",
      "Epoch 463/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 1.3802e-14 - mse: 1.3802e-14\n",
      "Epoch 464/1000\n",
      "32/32 [==============================] - 0s 569us/step - loss: 5.5902e-15 - mse: 5.5902e-15\n",
      "Epoch 465/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 4.9311e-15 - mse: 4.9311e-15\n",
      "Epoch 466/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 4.0154e-15 - mse: 4.0154e-15\n",
      "Epoch 467/1000\n",
      "32/32 [==============================] - 0s 585us/step - loss: 4.8774e-14 - mse: 4.8774e-14\n",
      "Epoch 468/1000\n",
      "32/32 [==============================] - 0s 752us/step - loss: 5.6026e-13 - mse: 5.6026e-13\n",
      "Epoch 469/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 2.8844e-13 - mse: 2.8844e-13\n",
      "Epoch 470/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 3.4109e-14 - mse: 3.4109e-14\n",
      "Epoch 471/1000\n",
      "32/32 [==============================] - 0s 554us/step - loss: 5.5253e-15 - mse: 5.5253e-15\n",
      "Epoch 472/1000\n",
      "32/32 [==============================] - 0s 577us/step - loss: 8.8357e-14 - mse: 8.8357e-14\n",
      "Epoch 473/1000\n",
      "32/32 [==============================] - 0s 562us/step - loss: 6.7721e-12 - mse: 6.7721e-12\n",
      "Epoch 474/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 6.1240e-11 - mse: 6.1240e-11\n",
      "Epoch 475/1000\n",
      "32/32 [==============================] - 0s 545us/step - loss: 5.4820e-10 - mse: 5.4820e-10\n",
      "Epoch 476/1000\n",
      "32/32 [==============================] - 0s 557us/step - loss: 5.0405e-11 - mse: 5.0405e-11\n",
      "Epoch 477/1000\n",
      "32/32 [==============================] - 0s 650us/step - loss: 6.9849e-11 - mse: 6.9849e-11\n",
      "Epoch 478/1000\n",
      "32/32 [==============================] - 0s 613us/step - loss: 8.3587e-07 - mse: 8.3587e-07\n",
      "Epoch 479/1000\n",
      "32/32 [==============================] - 0s 617us/step - loss: 2.7914e-06 - mse: 2.7914e-06\n",
      "Epoch 480/1000\n",
      "32/32 [==============================] - 0s 613us/step - loss: 1.6315e-07 - mse: 1.6315e-07\n",
      "Epoch 481/1000\n",
      "32/32 [==============================] - 0s 637us/step - loss: 8.3479e-09 - mse: 8.3479e-09\n",
      "Epoch 482/1000\n",
      "32/32 [==============================] - 0s 596us/step - loss: 2.1024e-10 - mse: 2.1024e-10\n",
      "Epoch 483/1000\n",
      "32/32 [==============================] - 0s 614us/step - loss: 7.9024e-11 - mse: 7.9024e-11\n",
      "Epoch 484/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 2.3470e-11 - mse: 2.3470e-11\n",
      "Epoch 485/1000\n",
      "32/32 [==============================] - 0s 630us/step - loss: 3.6950e-12 - mse: 3.6950e-12\n",
      "Epoch 486/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 6.0763e-12 - mse: 6.0763e-12\n",
      "Epoch 487/1000\n",
      "32/32 [==============================] - 0s 643us/step - loss: 1.0189e-12 - mse: 1.0189e-12\n",
      "Epoch 488/1000\n",
      "32/32 [==============================] - 0s 648us/step - loss: 3.7419e-13 - mse: 3.7419e-13\n",
      "Epoch 489/1000\n",
      "32/32 [==============================] - 0s 653us/step - loss: 9.9539e-14 - mse: 9.9539e-14\n",
      "Epoch 490/1000\n",
      "32/32 [==============================] - 0s 610us/step - loss: 3.4734e-14 - mse: 3.4734e-14\n",
      "Epoch 491/1000\n",
      "32/32 [==============================] - 0s 642us/step - loss: 1.8753e-13 - mse: 1.8753e-13\n",
      "Epoch 492/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 1.9589e-13 - mse: 1.9589e-13\n",
      "Epoch 493/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 4.4483e-14 - mse: 4.4483e-14\n",
      "Epoch 494/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 7.8281e-15 - mse: 7.8281e-15\n",
      "Epoch 495/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 4.8725e-15 - mse: 4.8725e-15\n",
      "Epoch 496/1000\n",
      "32/32 [==============================] - 0s 584us/step - loss: 4.5270e-14 - mse: 4.5270e-14\n",
      "Epoch 497/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 3.2435e-13 - mse: 3.2435e-13\n",
      "Epoch 498/1000\n",
      "32/32 [==============================] - 0s 652us/step - loss: 7.4373e-14 - mse: 7.4373e-14\n",
      "Epoch 499/1000\n",
      "32/32 [==============================] - 0s 644us/step - loss: 2.2111e-13 - mse: 2.2111e-13\n",
      "Epoch 500/1000\n",
      "32/32 [==============================] - 0s 662us/step - loss: 2.2734e-13 - mse: 2.2734e-13\n",
      "Epoch 501/1000\n",
      "32/32 [==============================] - 0s 660us/step - loss: 1.1027e-12 - mse: 1.1027e-12\n",
      "Epoch 502/1000\n",
      "32/32 [==============================] - 0s 586us/step - loss: 7.1281e-12 - mse: 7.1281e-12\n",
      "Epoch 503/1000\n",
      "32/32 [==============================] - 0s 599us/step - loss: 5.0228e-10 - mse: 5.0228e-10\n",
      "Epoch 504/1000\n",
      "32/32 [==============================] - 0s 619us/step - loss: 3.1465e-11 - mse: 3.1465e-11\n",
      "Epoch 505/1000\n",
      "32/32 [==============================] - 0s 571us/step - loss: 2.6063e-08 - mse: 2.6063e-08\n",
      "Epoch 506/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 2.4435e-07 - mse: 2.4435e-07\n",
      "Epoch 507/1000\n",
      "32/32 [==============================] - 0s 567us/step - loss: 5.2432e-08 - mse: 5.2432e-08\n",
      "Epoch 508/1000\n",
      "32/32 [==============================] - 0s 613us/step - loss: 4.9822e-08 - mse: 4.9822e-08\n",
      "Epoch 509/1000\n",
      "32/32 [==============================] - 0s 752us/step - loss: 5.2584e-07 - mse: 5.2584e-07\n",
      "Epoch 510/1000\n",
      "32/32 [==============================] - 0s 634us/step - loss: 5.1716e-07 - mse: 5.1716e-07\n",
      "Epoch 511/1000\n",
      "32/32 [==============================] - 0s 561us/step - loss: 7.7142e-07 - mse: 7.7142e-07\n",
      "Epoch 512/1000\n",
      "32/32 [==============================] - 0s 633us/step - loss: 4.1526e-08 - mse: 4.1526e-08\n",
      "Epoch 513/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 2.8308e-09 - mse: 2.8308e-09\n",
      "Epoch 514/1000\n",
      "32/32 [==============================] - 0s 577us/step - loss: 2.6000e-09 - mse: 2.6000e-09\n",
      "Epoch 515/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 1.9269e-09 - mse: 1.9269e-09\n",
      "Epoch 516/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 3.5124e-10 - mse: 3.5124e-10\n",
      "Epoch 517/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 4.4906e-11 - mse: 4.4906e-11\n",
      "Epoch 518/1000\n",
      "32/32 [==============================] - 0s 580us/step - loss: 5.4733e-11 - mse: 5.4733e-11\n",
      "Epoch 519/1000\n",
      "32/32 [==============================] - 0s 614us/step - loss: 6.2645e-11 - mse: 6.2645e-11\n",
      "Epoch 520/1000\n",
      "32/32 [==============================] - 0s 686us/step - loss: 1.1305e-11 - mse: 1.1305e-11\n",
      "Epoch 521/1000\n",
      "32/32 [==============================] - 0s 646us/step - loss: 1.2576e-12 - mse: 1.2576e-12\n",
      "Epoch 522/1000\n",
      "32/32 [==============================] - 0s 635us/step - loss: 2.3680e-12 - mse: 2.3680e-12\n",
      "Epoch 523/1000\n",
      "32/32 [==============================] - 0s 686us/step - loss: 4.3544e-12 - mse: 4.3544e-12\n",
      "Epoch 524/1000\n",
      "32/32 [==============================] - 0s 641us/step - loss: 9.5499e-11 - mse: 9.5499e-11\n",
      "Epoch 525/1000\n",
      "32/32 [==============================] - 0s 600us/step - loss: 2.8448e-08 - mse: 2.8448e-08\n",
      "Epoch 526/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 1.2693e-07 - mse: 1.2693e-07\n",
      "Epoch 527/1000\n",
      "32/32 [==============================] - 0s 634us/step - loss: 1.2092e-08 - mse: 1.2092e-08\n",
      "Epoch 528/1000\n",
      "32/32 [==============================] - 0s 792us/step - loss: 2.6162e-09 - mse: 2.6162e-09\n",
      "Epoch 529/1000\n",
      "32/32 [==============================] - 0s 686us/step - loss: 7.8652e-07 - mse: 7.8652e-07\n",
      "Epoch 530/1000\n",
      "32/32 [==============================] - 0s 649us/step - loss: 2.4250e-06 - mse: 2.4250e-06\n",
      "Epoch 531/1000\n",
      "32/32 [==============================] - 0s 644us/step - loss: 5.8462e-07 - mse: 5.8462e-07\n",
      "Epoch 532/1000\n",
      "32/32 [==============================] - 0s 572us/step - loss: 1.3511e-07 - mse: 1.3511e-07\n",
      "Epoch 533/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 9.0138e-09 - mse: 9.0138e-09\n",
      "Epoch 534/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 586us/step - loss: 1.2877e-09 - mse: 1.2877e-09\n",
      "Epoch 535/1000\n",
      "32/32 [==============================] - 0s 580us/step - loss: 2.3430e-10 - mse: 2.3430e-10\n",
      "Epoch 536/1000\n",
      "32/32 [==============================] - 0s 580us/step - loss: 1.0980e-10 - mse: 1.0980e-10\n",
      "Epoch 537/1000\n",
      "32/32 [==============================] - 0s 587us/step - loss: 7.9457e-11 - mse: 7.9457e-11\n",
      "Epoch 538/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 5.4286e-11 - mse: 5.4286e-11\n",
      "Epoch 539/1000\n",
      "32/32 [==============================] - 0s 844us/step - loss: 2.0162e-11 - mse: 2.0162e-11\n",
      "Epoch 540/1000\n",
      "32/32 [==============================] - 0s 733us/step - loss: 5.0717e-12 - mse: 5.0717e-12\n",
      "Epoch 541/1000\n",
      "32/32 [==============================] - 0s 769us/step - loss: 1.0893e-12 - mse: 1.0893e-12\n",
      "Epoch 542/1000\n",
      "32/32 [==============================] - 0s 632us/step - loss: 7.8222e-13 - mse: 7.8222e-13\n",
      "Epoch 543/1000\n",
      "32/32 [==============================] - 0s 629us/step - loss: 7.5211e-13 - mse: 7.5211e-13\n",
      "Epoch 544/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 1.5572e-13 - mse: 1.5572e-13\n",
      "Epoch 545/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 3.8892e-14 - mse: 3.8892e-14\n",
      "Epoch 546/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 6.3604e-15 - mse: 6.3604e-15\n",
      "Epoch 547/1000\n",
      "32/32 [==============================] - 0s 631us/step - loss: 7.7946e-15 - mse: 7.7946e-15\n",
      "Epoch 548/1000\n",
      "32/32 [==============================] - 0s 616us/step - loss: 4.9624e-15 - mse: 4.9624e-15\n",
      "Epoch 549/1000\n",
      "32/32 [==============================] - 0s 646us/step - loss: 3.3130e-15 - mse: 3.3130e-15\n",
      "Epoch 550/1000\n",
      "32/32 [==============================] - 0s 599us/step - loss: 4.1150e-15 - mse: 4.1150e-15\n",
      "Epoch 551/1000\n",
      "32/32 [==============================] - 0s 632us/step - loss: 1.4776e-13 - mse: 1.4776e-13\n",
      "Epoch 552/1000\n",
      "32/32 [==============================] - 0s 609us/step - loss: 4.8210e-13 - mse: 4.8210e-13\n",
      "Epoch 553/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 2.3399e-13 - mse: 2.3399e-13\n",
      "Epoch 554/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 1.8265e-13 - mse: 1.8265e-13\n",
      "Epoch 555/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 1.7460e-14 - mse: 1.7460e-14\n",
      "Epoch 556/1000\n",
      "32/32 [==============================] - 0s 625us/step - loss: 5.3188e-15 - mse: 5.3188e-15\n",
      "Epoch 557/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 4.8242e-15 - mse: 4.8242e-15\n",
      "Epoch 558/1000\n",
      "32/32 [==============================] - 0s 590us/step - loss: 3.0160e-13 - mse: 3.0160e-13\n",
      "Epoch 559/1000\n",
      "32/32 [==============================] - 0s 640us/step - loss: 4.4286e-10 - mse: 4.4286e-10\n",
      "Epoch 560/1000\n",
      "32/32 [==============================] - 0s 710us/step - loss: 1.6802e-06 - mse: 1.6802e-06\n",
      "Epoch 561/1000\n",
      "32/32 [==============================] - 0s 617us/step - loss: 6.8813e-06 - mse: 6.8813e-06\n",
      "Epoch 562/1000\n",
      "32/32 [==============================] - 0s 612us/step - loss: 1.1203e-07 - mse: 1.1203e-07\n",
      "Epoch 563/1000\n",
      "32/32 [==============================] - 0s 642us/step - loss: 1.1787e-08 - mse: 1.1787e-08\n",
      "Epoch 564/1000\n",
      "32/32 [==============================] - 0s 630us/step - loss: 4.0451e-09 - mse: 4.0451e-09\n",
      "Epoch 565/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 3.4423e-09 - mse: 3.4423e-09\n",
      "Epoch 566/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 1.1267e-09 - mse: 1.1267e-09\n",
      "Epoch 567/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 1.6464e-09 - mse: 1.6464e-09\n",
      "Epoch 568/1000\n",
      "32/32 [==============================] - 0s 631us/step - loss: 3.0468e-10 - mse: 3.0468e-10\n",
      "Epoch 569/1000\n",
      "32/32 [==============================] - 0s 652us/step - loss: 1.9708e-10 - mse: 1.9708e-10\n",
      "Epoch 570/1000\n",
      "32/32 [==============================] - 0s 695us/step - loss: 1.1018e-10 - mse: 1.1018e-10\n",
      "Epoch 571/1000\n",
      "32/32 [==============================] - 0s 647us/step - loss: 3.6487e-11 - mse: 3.6487e-11\n",
      "Epoch 572/1000\n",
      "32/32 [==============================] - 0s 614us/step - loss: 3.5060e-11 - mse: 3.5060e-11\n",
      "Epoch 573/1000\n",
      "32/32 [==============================] - 0s 593us/step - loss: 3.5215e-12 - mse: 3.5215e-12\n",
      "Epoch 574/1000\n",
      "32/32 [==============================] - 0s 613us/step - loss: 1.7731e-12 - mse: 1.7731e-12\n",
      "Epoch 575/1000\n",
      "32/32 [==============================] - 0s 647us/step - loss: 9.4684e-13 - mse: 9.4684e-13\n",
      "Epoch 576/1000\n",
      "32/32 [==============================] - 0s 645us/step - loss: 2.7486e-13 - mse: 2.7486e-13\n",
      "Epoch 577/1000\n",
      "32/32 [==============================] - 0s 622us/step - loss: 3.1787e-13 - mse: 3.1787e-13\n",
      "Epoch 578/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 1.9333e-13 - mse: 1.9333e-13\n",
      "Epoch 579/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 7.7558e-14 - mse: 7.7558e-14\n",
      "Epoch 580/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 1.3000e-14 - mse: 1.3000e-14\n",
      "Epoch 581/1000\n",
      "32/32 [==============================] - 0s 703us/step - loss: 8.1424e-15 - mse: 8.1424e-15\n",
      "Epoch 582/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 7.0766e-15 - mse: 7.0766e-15\n",
      "Epoch 583/1000\n",
      "32/32 [==============================] - 0s 618us/step - loss: 6.6650e-15 - mse: 6.6650e-15\n",
      "Epoch 584/1000\n",
      "32/32 [==============================] - 0s 582us/step - loss: 8.6047e-15 - mse: 8.6047e-15\n",
      "Epoch 585/1000\n",
      "32/32 [==============================] - 0s 581us/step - loss: 1.0279e-14 - mse: 1.0279e-14\n",
      "Epoch 586/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 3.5533e-15 - mse: 3.5533e-15\n",
      "Epoch 587/1000\n",
      "32/32 [==============================] - 0s 596us/step - loss: 3.8880e-15 - mse: 3.8880e-15\n",
      "Epoch 588/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 6.9256e-15 - mse: 6.9256e-15\n",
      "Epoch 589/1000\n",
      "32/32 [==============================] - 0s 584us/step - loss: 5.0726e-15 - mse: 5.0726e-15\n",
      "Epoch 590/1000\n",
      "32/32 [==============================] - 0s 672us/step - loss: 4.0757e-15 - mse: 4.0757e-15\n",
      "Epoch 591/1000\n",
      "32/32 [==============================] - 0s 613us/step - loss: 8.5705e-15 - mse: 8.5705e-15\n",
      "Epoch 592/1000\n",
      "32/32 [==============================] - 0s 619us/step - loss: 1.1294e-14 - mse: 1.1294e-14\n",
      "Epoch 593/1000\n",
      "32/32 [==============================] - 0s 559us/step - loss: 2.9148e-15 - mse: 2.9148e-15\n",
      "Epoch 594/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 3.9253e-15 - mse: 3.9253e-15\n",
      "Epoch 595/1000\n",
      "32/32 [==============================] - 0s 569us/step - loss: 8.2285e-15 - mse: 8.2285e-15\n",
      "Epoch 596/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 6.1892e-15 - mse: 6.1892e-15\n",
      "Epoch 597/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 6.8924e-15 - mse: 6.8924e-15\n",
      "Epoch 598/1000\n",
      "32/32 [==============================] - 0s 608us/step - loss: 9.2587e-14 - mse: 9.2587e-14\n",
      "Epoch 599/1000\n",
      "32/32 [==============================] - 0s 751us/step - loss: 1.3293e-13 - mse: 1.3293e-13\n",
      "Epoch 600/1000\n",
      "32/32 [==============================] - 0s 663us/step - loss: 9.1848e-14 - mse: 9.1848e-14\n",
      "Epoch 601/1000\n",
      "32/32 [==============================] - 0s 677us/step - loss: 1.5956e-13 - mse: 1.5956e-13\n",
      "Epoch 602/1000\n",
      "32/32 [==============================] - 0s 657us/step - loss: 2.4923e-13 - mse: 2.4923e-13\n",
      "Epoch 603/1000\n",
      "32/32 [==============================] - 0s 639us/step - loss: 1.0581e-13 - mse: 1.0581e-13\n",
      "Epoch 604/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 1.2569e-12 - mse: 1.2569e-12\n",
      "Epoch 605/1000\n",
      "32/32 [==============================] - 0s 625us/step - loss: 2.5925e-13 - mse: 2.5925e-13\n",
      "Epoch 606/1000\n",
      "32/32 [==============================] - 0s 637us/step - loss: 4.9593e-13 - mse: 4.9593e-13\n",
      "Epoch 607/1000\n",
      "32/32 [==============================] - 0s 636us/step - loss: 1.0345e-11 - mse: 1.0345e-11\n",
      "Epoch 608/1000\n",
      "32/32 [==============================] - 0s 638us/step - loss: 1.4375e-09 - mse: 1.4375e-09\n",
      "Epoch 609/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 9.3660e-07 - mse: 9.3660e-07\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 685us/step - loss: 3.0097e-06 - mse: 3.0097e-06\n",
      "Epoch 611/1000\n",
      "32/32 [==============================] - 0s 772us/step - loss: 4.2297e-07 - mse: 4.2297e-07\n",
      "Epoch 612/1000\n",
      "32/32 [==============================] - 0s 695us/step - loss: 1.7093e-08 - mse: 1.7093e-08\n",
      "Epoch 613/1000\n",
      "32/32 [==============================] - 0s 635us/step - loss: 3.6171e-09 - mse: 3.6171e-09\n",
      "Epoch 614/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 1.0043e-09 - mse: 1.0043e-09\n",
      "Epoch 615/1000\n",
      "32/32 [==============================] - 0s 622us/step - loss: 1.2314e-10 - mse: 1.2314e-10\n",
      "Epoch 616/1000\n",
      "32/32 [==============================] - 0s 586us/step - loss: 6.2772e-11 - mse: 6.2772e-11\n",
      "Epoch 617/1000\n",
      "32/32 [==============================] - 0s 571us/step - loss: 4.7386e-11 - mse: 4.7386e-11\n",
      "Epoch 618/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 2.6302e-11 - mse: 2.6302e-11\n",
      "Epoch 619/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 4.3775e-12 - mse: 4.3775e-12\n",
      "Epoch 620/1000\n",
      "32/32 [==============================] - 0s 557us/step - loss: 1.2499e-12 - mse: 1.2499e-12\n",
      "Epoch 621/1000\n",
      "32/32 [==============================] - 0s 605us/step - loss: 1.4917e-12 - mse: 1.4917e-12\n",
      "Epoch 622/1000\n",
      "32/32 [==============================] - 0s 677us/step - loss: 1.2869e-12 - mse: 1.2869e-12\n",
      "Epoch 623/1000\n",
      "32/32 [==============================] - 0s 596us/step - loss: 3.7452e-13 - mse: 3.7452e-13\n",
      "Epoch 624/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 3.2545e-14 - mse: 3.2545e-14\n",
      "Epoch 625/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 1.9396e-14 - mse: 1.9396e-14\n",
      "Epoch 626/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 4.6885e-14 - mse: 4.6885e-14\n",
      "Epoch 627/1000\n",
      "32/32 [==============================] - 0s 606us/step - loss: 4.4760e-14 - mse: 4.4760e-14\n",
      "Epoch 628/1000\n",
      "32/32 [==============================] - 0s 599us/step - loss: 7.4452e-14 - mse: 7.4452e-14\n",
      "Epoch 629/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 1.4382e-13 - mse: 1.4382e-13\n",
      "Epoch 630/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 8.7984e-14 - mse: 8.7984e-14\n",
      "Epoch 631/1000\n",
      "32/32 [==============================] - 0s 625us/step - loss: 4.0766e-14 - mse: 4.0766e-14\n",
      "Epoch 632/1000\n",
      "32/32 [==============================] - 0s 656us/step - loss: 1.8750e-13 - mse: 1.8750e-13\n",
      "Epoch 633/1000\n",
      "32/32 [==============================] - 0s 676us/step - loss: 2.3482e-11 - mse: 2.3482e-11\n",
      "Epoch 634/1000\n",
      "32/32 [==============================] - 0s 648us/step - loss: 4.1985e-11 - mse: 4.1985e-11\n",
      "Epoch 635/1000\n",
      "32/32 [==============================] - 0s 611us/step - loss: 1.3496e-11 - mse: 1.3496e-11\n",
      "Epoch 636/1000\n",
      "32/32 [==============================] - 0s 615us/step - loss: 1.2582e-09 - mse: 1.2582e-09\n",
      "Epoch 637/1000\n",
      "32/32 [==============================] - 0s 571us/step - loss: 1.3714e-09 - mse: 1.3714e-09\n",
      "Epoch 638/1000\n",
      "32/32 [==============================] - 0s 575us/step - loss: 9.4299e-11 - mse: 9.4299e-11\n",
      "Epoch 639/1000\n",
      "32/32 [==============================] - 0s 621us/step - loss: 1.2120e-09 - mse: 1.2120e-09\n",
      "Epoch 640/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 7.8393e-09 - mse: 7.8393e-09\n",
      "Epoch 641/1000\n",
      "32/32 [==============================] - 0s 655us/step - loss: 1.4513e-07 - mse: 1.4513e-07\n",
      "Epoch 642/1000\n",
      "32/32 [==============================] - 0s 644us/step - loss: 6.3191e-07 - mse: 6.3191e-07\n",
      "Epoch 643/1000\n",
      "32/32 [==============================] - 0s 710us/step - loss: 6.3651e-07 - mse: 6.3651e-07\n",
      "Epoch 644/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 2.2597e-07 - mse: 2.2597e-07\n",
      "Epoch 645/1000\n",
      "32/32 [==============================] - 0s 642us/step - loss: 2.9661e-08 - mse: 2.9661e-08\n",
      "Epoch 646/1000\n",
      "32/32 [==============================] - 0s 583us/step - loss: 9.4944e-10 - mse: 9.4944e-10\n",
      "Epoch 647/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 5.4214e-11 - mse: 5.4214e-11\n",
      "Epoch 648/1000\n",
      "32/32 [==============================] - 0s 664us/step - loss: 2.0282e-11 - mse: 2.0282e-11\n",
      "Epoch 649/1000\n",
      "32/32 [==============================] - 0s 637us/step - loss: 1.2035e-11 - mse: 1.2035e-11\n",
      "Epoch 650/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 1.3054e-11 - mse: 1.3054e-11\n",
      "Epoch 651/1000\n",
      "32/32 [==============================] - 0s 617us/step - loss: 1.5323e-11 - mse: 1.5323e-11\n",
      "Epoch 652/1000\n",
      "32/32 [==============================] - 0s 716us/step - loss: 7.3424e-12 - mse: 7.3424e-12\n",
      "Epoch 653/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 2.0662e-13 - mse: 2.0662e-13\n",
      "Epoch 654/1000\n",
      "32/32 [==============================] - 0s 656us/step - loss: 5.2841e-12 - mse: 5.2841e-12\n",
      "Epoch 655/1000\n",
      "32/32 [==============================] - 0s 601us/step - loss: 9.5442e-12 - mse: 9.5442e-12\n",
      "Epoch 656/1000\n",
      "32/32 [==============================] - 0s 581us/step - loss: 2.7792e-10 - mse: 2.7792e-10\n",
      "Epoch 657/1000\n",
      "32/32 [==============================] - 0s 600us/step - loss: 5.5943e-09 - mse: 5.5943e-09\n",
      "Epoch 658/1000\n",
      "32/32 [==============================] - 0s 614us/step - loss: 9.2858e-09 - mse: 9.2858e-09\n",
      "Epoch 659/1000\n",
      "32/32 [==============================] - 0s 642us/step - loss: 4.9192e-07 - mse: 4.9192e-07\n",
      "Epoch 660/1000\n",
      "32/32 [==============================] - 0s 628us/step - loss: 1.0872e-06 - mse: 1.0872e-06\n",
      "Epoch 661/1000\n",
      "32/32 [==============================] - 0s 585us/step - loss: 5.1591e-07 - mse: 5.1591e-07\n",
      "Epoch 662/1000\n",
      "32/32 [==============================] - 0s 673us/step - loss: 6.9341e-08 - mse: 6.9341e-08\n",
      "Epoch 663/1000\n",
      "32/32 [==============================] - 0s 663us/step - loss: 7.4637e-09 - mse: 7.4637e-09\n",
      "Epoch 664/1000\n",
      "32/32 [==============================] - 0s 637us/step - loss: 1.0206e-09 - mse: 1.0206e-09\n",
      "Epoch 665/1000\n",
      "32/32 [==============================] - 0s 576us/step - loss: 9.3968e-10 - mse: 9.3968e-10\n",
      "Epoch 666/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 9.8572e-10 - mse: 9.8572e-10\n",
      "Epoch 667/1000\n",
      "32/32 [==============================] - 0s 611us/step - loss: 3.5641e-09 - mse: 3.5641e-09\n",
      "Epoch 668/1000\n",
      "32/32 [==============================] - 0s 559us/step - loss: 2.5696e-09 - mse: 2.5696e-09\n",
      "Epoch 669/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 6.4607e-10 - mse: 6.4607e-10\n",
      "Epoch 670/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 1.3743e-10 - mse: 1.3743e-10\n",
      "Epoch 671/1000\n",
      "32/32 [==============================] - 0s 619us/step - loss: 2.2101e-10 - mse: 2.2101e-10\n",
      "Epoch 672/1000\n",
      "32/32 [==============================] - 0s 565us/step - loss: 5.7553e-10 - mse: 5.7553e-10\n",
      "Epoch 673/1000\n",
      "32/32 [==============================] - 0s 574us/step - loss: 5.4971e-10 - mse: 5.4971e-10\n",
      "Epoch 674/1000\n",
      "32/32 [==============================] - 0s 700us/step - loss: 9.2207e-11 - mse: 9.2207e-11\n",
      "Epoch 675/1000\n",
      "32/32 [==============================] - 0s 658us/step - loss: 1.7478e-10 - mse: 1.7478e-10\n",
      "Epoch 676/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 5.8828e-11 - mse: 5.8828e-11\n",
      "Epoch 677/1000\n",
      "32/32 [==============================] - 0s 606us/step - loss: 2.3315e-11 - mse: 2.3315e-11\n",
      "Epoch 678/1000\n",
      "32/32 [==============================] - 0s 619us/step - loss: 2.5485e-08 - mse: 2.5485e-08\n",
      "Epoch 679/1000\n",
      "32/32 [==============================] - 0s 611us/step - loss: 1.8080e-07 - mse: 1.8080e-07\n",
      "Epoch 680/1000\n",
      "32/32 [==============================] - 0s 599us/step - loss: 1.4011e-07 - mse: 1.4011e-07\n",
      "Epoch 681/1000\n",
      "32/32 [==============================] - 0s 614us/step - loss: 5.9944e-07 - mse: 5.9944e-07\n",
      "Epoch 682/1000\n",
      "32/32 [==============================] - 0s 591us/step - loss: 3.4428e-08 - mse: 3.4428e-08\n",
      "Epoch 683/1000\n",
      "32/32 [==============================] - 0s 607us/step - loss: 5.3179e-08 - mse: 5.3179e-08\n",
      "Epoch 684/1000\n",
      "32/32 [==============================] - 0s 774us/step - loss: 1.0795e-07 - mse: 1.0795e-07\n",
      "Epoch 685/1000\n",
      "32/32 [==============================] - 0s 636us/step - loss: 3.4238e-08 - mse: 3.4238e-08\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 675us/step - loss: 3.5241e-09 - mse: 3.5241e-09\n",
      "Epoch 687/1000\n",
      "32/32 [==============================] - 0s 613us/step - loss: 5.0877e-09 - mse: 5.0877e-09\n",
      "Epoch 688/1000\n",
      "32/32 [==============================] - 0s 666us/step - loss: 1.8489e-10 - mse: 1.8489e-10\n",
      "Epoch 689/1000\n",
      "32/32 [==============================] - 0s 639us/step - loss: 3.0066e-09 - mse: 3.0066e-09\n",
      "Epoch 690/1000\n",
      "32/32 [==============================] - 0s 692us/step - loss: 9.3277e-07 - mse: 9.3277e-07\n",
      "Epoch 691/1000\n",
      "32/32 [==============================] - 0s 620us/step - loss: 5.7449e-07 - mse: 5.7449e-07\n",
      "Epoch 692/1000\n",
      "32/32 [==============================] - 0s 593us/step - loss: 9.7479e-08 - mse: 9.7479e-08\n",
      "Epoch 693/1000\n",
      "32/32 [==============================] - 0s 655us/step - loss: 1.2531e-08 - mse: 1.2531e-08\n",
      "Epoch 694/1000\n",
      "32/32 [==============================] - 0s 737us/step - loss: 1.2500e-09 - mse: 1.2500e-09\n",
      "Epoch 695/1000\n",
      "32/32 [==============================] - 0s 626us/step - loss: 1.4882e-09 - mse: 1.4882e-09\n",
      "Epoch 696/1000\n",
      "32/32 [==============================] - 0s 625us/step - loss: 1.4835e-10 - mse: 1.4835e-10\n",
      "Epoch 697/1000\n",
      "32/32 [==============================] - 0s 645us/step - loss: 4.2700e-12 - mse: 4.2700e-12\n",
      "Epoch 698/1000\n",
      "32/32 [==============================] - 0s 652us/step - loss: 3.6845e-13 - mse: 3.6845e-13\n",
      "Epoch 699/1000\n",
      "32/32 [==============================] - 0s 629us/step - loss: 1.1731e-13 - mse: 1.1731e-13\n",
      "Epoch 700/1000\n",
      "32/32 [==============================] - 0s 600us/step - loss: 3.1126e-14 - mse: 3.1126e-14\n",
      "Epoch 701/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 1.8918e-14 - mse: 1.8918e-14\n",
      "Epoch 702/1000\n",
      "32/32 [==============================] - 0s 559us/step - loss: 4.8394e-13 - mse: 4.8394e-13\n",
      "Epoch 703/1000\n",
      "32/32 [==============================] - 0s 624us/step - loss: 2.7336e-12 - mse: 2.7336e-12\n",
      "Epoch 704/1000\n",
      "32/32 [==============================] - 0s 779us/step - loss: 4.4774e-11 - mse: 4.4774e-11\n",
      "Epoch 705/1000\n",
      "32/32 [==============================] - 0s 640us/step - loss: 2.1220e-09 - mse: 2.1220e-09\n",
      "Epoch 706/1000\n",
      "32/32 [==============================] - 0s 654us/step - loss: 2.6717e-08 - mse: 2.6717e-08\n",
      "Epoch 707/1000\n",
      "32/32 [==============================] - 0s 630us/step - loss: 9.7324e-07 - mse: 9.7324e-07\n",
      "Epoch 708/1000\n",
      "32/32 [==============================] - 0s 677us/step - loss: 7.1880e-07 - mse: 7.1880e-07\n",
      "Epoch 709/1000\n",
      "32/32 [==============================] - 0s 597us/step - loss: 7.4383e-08 - mse: 7.4383e-08\n",
      "Epoch 710/1000\n",
      "32/32 [==============================] - 0s 623us/step - loss: 2.4079e-08 - mse: 2.4079e-08\n",
      "Epoch 711/1000\n",
      "32/32 [==============================] - 0s 589us/step - loss: 6.0841e-09 - mse: 6.0841e-09\n",
      "Epoch 712/1000\n",
      "32/32 [==============================] - 0s 642us/step - loss: 8.7523e-09 - mse: 8.7523e-09\n",
      "Epoch 713/1000\n",
      "32/32 [==============================] - 0s 619us/step - loss: 7.9343e-09 - mse: 7.9343e-09\n",
      "Epoch 714/1000\n",
      "32/32 [==============================] - 0s 655us/step - loss: 1.3599e-09 - mse: 1.3599e-09\n",
      "Epoch 715/1000\n",
      "32/32 [==============================] - 0s 563us/step - loss: 7.5667e-10 - mse: 7.5667e-10\n",
      "Epoch 716/1000\n",
      "32/32 [==============================] - 0s 578us/step - loss: 7.9339e-10 - mse: 7.9339e-10\n",
      "Epoch 717/1000\n",
      "32/32 [==============================] - 0s 634us/step - loss: 6.5331e-10 - mse: 6.5331e-10\n",
      "Epoch 718/1000\n",
      "32/32 [==============================] - 0s 683us/step - loss: 6.6223e-10 - mse: 6.6223e-10\n",
      "Epoch 719/1000\n",
      "32/32 [==============================] - 0s 631us/step - loss: 1.1020e-09 - mse: 1.1020e-09\n",
      "Epoch 720/1000\n",
      "32/32 [==============================] - 0s 626us/step - loss: 5.4926e-10 - mse: 5.4926e-10\n",
      "Epoch 721/1000\n",
      "32/32 [==============================] - 0s 565us/step - loss: 7.5839e-10 - mse: 7.5839e-10\n",
      "Epoch 722/1000\n",
      "32/32 [==============================] - 0s 564us/step - loss: 8.3979e-10 - mse: 8.3979e-10\n",
      "Epoch 723/1000\n",
      "32/32 [==============================] - 0s 555us/step - loss: 4.5809e-09 - mse: 4.5809e-09\n",
      "Epoch 724/1000\n",
      "32/32 [==============================] - 0s 720us/step - loss: 5.4694e-07 - mse: 5.4694e-07\n",
      "Epoch 725/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 1.6939e-08 - mse: 1.6939e-08\n",
      "Epoch 726/1000\n",
      "32/32 [==============================] - 0s 569us/step - loss: 2.8399e-08 - mse: 2.8399e-08\n",
      "Epoch 727/1000\n",
      "32/32 [==============================] - 0s 563us/step - loss: 6.7738e-09 - mse: 6.7738e-09\n",
      "Epoch 728/1000\n",
      "32/32 [==============================] - 0s 534us/step - loss: 1.5980e-09 - mse: 1.5980e-09\n",
      "Epoch 729/1000\n",
      "32/32 [==============================] - 0s 565us/step - loss: 6.7794e-09 - mse: 6.7794e-09\n",
      "Epoch 730/1000\n",
      "32/32 [==============================] - 0s 557us/step - loss: 1.7744e-08 - mse: 1.7744e-08\n",
      "Epoch 731/1000\n",
      "32/32 [==============================] - 0s 537us/step - loss: 6.2249e-08 - mse: 6.2249e-08\n",
      "Epoch 732/1000\n",
      "32/32 [==============================] - 0s 528us/step - loss: 4.7105e-07 - mse: 4.7105e-07\n",
      "Epoch 733/1000\n",
      "32/32 [==============================] - 0s 525us/step - loss: 4.3152e-07 - mse: 4.3152e-07\n",
      "Epoch 734/1000\n",
      "32/32 [==============================] - 0s 541us/step - loss: 7.5385e-07 - mse: 7.5385e-07\n",
      "Epoch 735/1000\n",
      "32/32 [==============================] - 0s 556us/step - loss: 5.4950e-07 - mse: 5.4950e-07\n",
      "Epoch 736/1000\n",
      "32/32 [==============================] - 0s 650us/step - loss: 7.1401e-08 - mse: 7.1401e-08\n",
      "Epoch 737/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 1.1458e-08 - mse: 1.1458e-08\n",
      "Epoch 738/1000\n",
      "32/32 [==============================] - 0s 597us/step - loss: 1.7775e-09 - mse: 1.7775e-09\n",
      "Epoch 739/1000\n",
      "32/32 [==============================] - 0s 556us/step - loss: 4.5076e-11 - mse: 4.5076e-11\n",
      "Epoch 740/1000\n",
      "32/32 [==============================] - 0s 550us/step - loss: 2.2034e-12 - mse: 2.2034e-12\n",
      "Epoch 741/1000\n",
      "32/32 [==============================] - 0s 539us/step - loss: 2.1471e-12 - mse: 2.1471e-12\n",
      "Epoch 742/1000\n",
      "32/32 [==============================] - 0s 564us/step - loss: 5.9838e-13 - mse: 5.9838e-13\n",
      "Epoch 743/1000\n",
      "32/32 [==============================] - 0s 546us/step - loss: 4.8547e-13 - mse: 4.8547e-13\n",
      "Epoch 744/1000\n",
      "32/32 [==============================] - 0s 545us/step - loss: 6.0087e-13 - mse: 6.0087e-13\n",
      "Epoch 745/1000\n",
      "32/32 [==============================] - 0s 526us/step - loss: 2.4383e-12 - mse: 2.4383e-12\n",
      "Epoch 746/1000\n",
      "32/32 [==============================] - 0s 534us/step - loss: 5.5793e-13 - mse: 5.5793e-13\n",
      "Epoch 747/1000\n",
      "32/32 [==============================] - 0s 543us/step - loss: 6.6230e-14 - mse: 6.6230e-14\n",
      "Epoch 748/1000\n",
      "32/32 [==============================] - 0s 674us/step - loss: 9.4529e-13 - mse: 9.4529e-13\n",
      "Epoch 749/1000\n",
      "32/32 [==============================] - 0s 655us/step - loss: 3.1479e-12 - mse: 3.1479e-12\n",
      "Epoch 750/1000\n",
      "32/32 [==============================] - 0s 709us/step - loss: 4.7039e-13 - mse: 4.7039e-13\n",
      "Epoch 751/1000\n",
      "32/32 [==============================] - 0s 602us/step - loss: 1.3667e-11 - mse: 1.3667e-11\n",
      "Epoch 752/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 2.1166e-09 - mse: 2.1166e-09\n",
      "Epoch 753/1000\n",
      "32/32 [==============================] - 0s 644us/step - loss: 2.7706e-08 - mse: 2.7706e-08\n",
      "Epoch 754/1000\n",
      "32/32 [==============================] - 0s 585us/step - loss: 3.2926e-07 - mse: 3.2926e-07\n",
      "Epoch 755/1000\n",
      "32/32 [==============================] - 0s 666us/step - loss: 1.1064e-06 - mse: 1.1064e-06\n",
      "Epoch 756/1000\n",
      "32/32 [==============================] - 0s 614us/step - loss: 1.8135e-08 - mse: 1.8135e-08\n",
      "Epoch 757/1000\n",
      "32/32 [==============================] - 0s 603us/step - loss: 2.6287e-09 - mse: 2.6287e-09\n",
      "Epoch 758/1000\n",
      "32/32 [==============================] - 0s 598us/step - loss: 6.4130e-09 - mse: 6.4130e-09\n",
      "Epoch 759/1000\n",
      "32/32 [==============================] - 0s 639us/step - loss: 6.1403e-10 - mse: 6.1403e-10\n",
      "Epoch 760/1000\n",
      "32/32 [==============================] - 0s 686us/step - loss: 1.7772e-10 - mse: 1.7772e-10\n",
      "Epoch 761/1000\n",
      "32/32 [==============================] - 0s 905us/step - loss: 3.1962e-11 - mse: 3.1962e-11\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 681us/step - loss: 2.2736e-10 - mse: 2.2736e-10\n",
      "Epoch 763/1000\n",
      "32/32 [==============================] - 0s 630us/step - loss: 8.1273e-10 - mse: 8.1273e-10\n",
      "Epoch 764/1000\n",
      "32/32 [==============================] - 0s 648us/step - loss: 7.9726e-09 - mse: 7.9726e-09\n",
      "Epoch 765/1000\n",
      "32/32 [==============================] - 0s 628us/step - loss: 6.3691e-09 - mse: 6.3691e-09\n",
      "Epoch 766/1000\n",
      "32/32 [==============================] - 0s 638us/step - loss: 7.7797e-09 - mse: 7.7797e-09\n",
      "Epoch 767/1000\n",
      "32/32 [==============================] - 0s 565us/step - loss: 2.9964e-07 - mse: 2.9964e-07\n",
      "Epoch 768/1000\n",
      "32/32 [==============================] - 0s 618us/step - loss: 2.7138e-07 - mse: 2.7138e-07\n",
      "Epoch 769/1000\n",
      "32/32 [==============================] - 0s 699us/step - loss: 1.8769e-07 - mse: 1.8769e-07\n",
      "Epoch 770/1000\n",
      "32/32 [==============================] - 0s 622us/step - loss: 1.4476e-07 - mse: 1.4476e-07\n",
      "Epoch 771/1000\n",
      "32/32 [==============================] - 0s 595us/step - loss: 1.1270e-07 - mse: 1.1270e-07\n",
      "Epoch 772/1000\n",
      "32/32 [==============================] - 0s 550us/step - loss: 7.0011e-09 - mse: 7.0011e-09\n",
      "Epoch 773/1000\n",
      "32/32 [==============================] - 0s 606us/step - loss: 2.1763e-09 - mse: 2.1763e-09\n",
      "Epoch 774/1000\n",
      "32/32 [==============================] - 0s 648us/step - loss: 4.2924e-10 - mse: 4.2924e-10\n",
      "Epoch 775/1000\n",
      "32/32 [==============================] - 0s 638us/step - loss: 5.1194e-10 - mse: 5.1194e-10\n",
      "Epoch 776/1000\n",
      "32/32 [==============================] - 0s 710us/step - loss: 7.7938e-09 - mse: 7.7938e-09\n",
      "Epoch 777/1000\n",
      "32/32 [==============================] - 0s 627us/step - loss: 2.3331e-07 - mse: 2.3331e-07\n",
      "Epoch 778/1000\n",
      "32/32 [==============================] - 0s 649us/step - loss: 1.2665e-07 - mse: 1.2665e-07\n",
      "Epoch 779/1000\n",
      "32/32 [==============================] - 0s 679us/step - loss: 5.8958e-07 - mse: 5.8958e-07\n",
      "Epoch 780/1000\n",
      "32/32 [==============================] - 0s 618us/step - loss: 5.4913e-06 - mse: 5.4913e-06\n",
      "Epoch 781/1000\n",
      "32/32 [==============================] - 0s 644us/step - loss: 3.9670e-07 - mse: 3.9670e-07\n",
      "Epoch 782/1000\n",
      "32/32 [==============================] - 0s 630us/step - loss: 8.0376e-08 - mse: 8.0376e-08\n",
      "Epoch 783/1000\n",
      "32/32 [==============================] - 0s 634us/step - loss: 9.7585e-09 - mse: 9.7585e-09\n",
      "Epoch 784/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 1.0860e-09 - mse: 1.0860e-09\n",
      "Epoch 785/1000\n",
      "32/32 [==============================] - 0s 632us/step - loss: 1.1436e-10 - mse: 1.1436e-10\n",
      "Epoch 786/1000\n",
      "32/32 [==============================] - 0s 592us/step - loss: 1.1781e-11 - mse: 1.1781e-11\n",
      "Epoch 787/1000\n",
      "32/32 [==============================] - 0s 579us/step - loss: 2.2682e-12 - mse: 2.2682e-12\n",
      "Epoch 788/1000\n",
      "32/32 [==============================] - 0s 554us/step - loss: 5.6670e-13 - mse: 5.6670e-13\n",
      "Epoch 789/1000\n",
      "32/32 [==============================] - 0s 588us/step - loss: 1.1951e-13 - mse: 1.1951e-13\n",
      "Epoch 790/1000\n",
      "32/32 [==============================] - 0s 574us/step - loss: 2.9798e-14 - mse: 2.9798e-14\n",
      "Epoch 791/1000\n",
      "32/32 [==============================] - 0s 611us/step - loss: 9.1499e-15 - mse: 9.1499e-15\n",
      "Epoch 792/1000\n",
      "32/32 [==============================] - 0s 600us/step - loss: 4.2277e-15 - mse: 4.2277e-15\n",
      "Epoch 793/1000\n",
      "32/32 [==============================] - 0s 688us/step - loss: 3.7225e-15 - mse: 3.7225e-15\n",
      "Epoch 794/1000\n",
      "32/32 [==============================] - 0s 638us/step - loss: 7.7797e-15 - mse: 7.7797e-15\n",
      "Epoch 795/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 4.9812e-15 - mse: 4.9812e-15\n",
      "Epoch 796/1000\n",
      "32/32 [==============================] - 0s 632us/step - loss: 2.9169e-15 - mse: 2.9169e-15\n",
      "Epoch 797/1000\n",
      "32/32 [==============================] - 0s 604us/step - loss: 7.1605e-15 - mse: 7.1605e-15\n",
      "Epoch 798/1000\n",
      "32/32 [==============================] - 0s 634us/step - loss: 6.7129e-15 - mse: 6.7129e-15\n",
      "Epoch 799/1000\n",
      "32/32 [==============================] - 0s 630us/step - loss: 4.2161e-15 - mse: 4.2161e-15\n",
      "Epoch 800/1000\n",
      "32/32 [==============================] - 0s 615us/step - loss: 4.8607e-15 - mse: 4.8607e-15\n",
      "Epoch 801/1000\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.2035e-15 - mse: 2.2035e-15"
     ]
    }
   ],
   "source": [
    "# fit the model onto our dataset and run for 100 epochs\n",
    "model.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at 20 data points and see how we do\n",
    "for x, y in zip(X_train[0:80:4], Y_train[0:80:4]):\n",
    "    print(\"X = {}, Y = {}, Predicted - {}\".format(x, y, model.predict([[x[0], x[1]]])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
